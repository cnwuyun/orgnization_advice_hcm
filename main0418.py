import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
import japanize_matplotlib
import random
import functools
from concurrent.futures import ThreadPoolExecutor


# 1. ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæ–°ã—ã„ã‚¹ã‚­ãƒ«ä½“ç³»ï¼‰
def prepare_data():
    skills = ['å¿ƒèº«å¥å…¨æ€§', 'äººæ ¼ã¨å¿—', 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ', 'æ¥­å‹™èƒ½åŠ›', 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›', 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾']

    position_requirements = {
        "ç¤¾é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 5 for s in skills if s != 'æ¥­å‹™èƒ½åŠ›'},
            "é‡ã¿": {'å¿ƒèº«å¥å…¨æ€§': 0.2, 'äººæ ¼ã¨å¿—': 0.25, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.2, 'æ¥­å‹™èƒ½åŠ›': 0.1,
                     'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.15, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.1},
            "éšå±¤": 1,
            "èª¬æ˜": "å…¨ç¤¾ã®ãƒ“ã‚¸ãƒ§ãƒ³ç­–å®šã¨çµŒå–¶åˆ¤æ–­ãŒä¸»è¦ãªå½¹å‰²",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["çµŒå–¶", "ãƒ“ã‚¸ãƒ§ãƒ³", "åˆ¤æ–­åŠ›", "æ±ºæ–­åŠ›"]
        },
        "çµŒå–¶ä¼ç”»æœ¬éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {'å¿ƒèº«å¥å…¨æ€§': 0.15, 'äººæ ¼ã¨å¿—': 0.2, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.15, 'æ¥­å‹™èƒ½åŠ›': 0.15,
                     'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.25, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.1},
            "éšå±¤": 2,
            "èª¬æ˜": "ä¸­é•·æœŸçµŒå–¶è¨ˆç”»ã®ç­–å®šã¨å®Ÿè¡Œç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["è¨ˆç”»", "ã‚·ãƒŠãƒªã‚ª", "åˆ†æ", "æˆ¦ç•¥"]
        },
        "äº‹æ¥­éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {'å¿ƒèº«å¥å…¨æ€§': 0.15, 'äººæ ¼ã¨å¿—': 0.15, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.15, 'æ¥­å‹™èƒ½åŠ›': 0.25,
                     'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.2, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.1},
            "éšå±¤": 2,
            "èª¬æ˜": "äº‹æ¥­å˜ä½ã®P&Lè²¬ä»»ã¨æˆ¦ç•¥å®Ÿè¡Œ",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["äº‹æ¥­", "åç›Š", "é¡§å®¢", "å¸‚å ´"]
        },
        "å†…éƒ¨ç›£æŸ»éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«":  {s: 3 for s in skills},
            "é‡ã¿": {
                'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.3,
                'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.25,
                'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.2,
                'å¿ƒèº«å¥å…¨æ€§': 0.1,
                'äººæ ¼ã¨å¿—': 0.1,
                'æ¥­å‹™èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "ä¼æ¥­çµ±æ²»ã¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã®å¾¹åº•çš„ãªç›£æŸ»ãƒ»ç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["ç›£æŸ»", "ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹", "ãƒªã‚¹ã‚¯ç®¡ç†", "ã‚¬ãƒãƒŠãƒ³ã‚¹"]
        },
        "Aäº‹æ¥­éƒ¨ãƒ»æ±äº¬æ”¯ç¤¾é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 3 for s in skills},
            "é‡ã¿": {
                'æ¥­å‹™èƒ½åŠ›': 0.3,
                'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.25,
                'å¿ƒèº«å¥å…¨æ€§': 0.15,
                'äººæ ¼ã¨å¿—': 0.15,
                'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.1,
                'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "æ±äº¬åœ°åŸŸã«ãŠã‘ã‚‹äº‹æ¥­æˆ¦ç•¥ã®å®Ÿè¡Œã¨å–¶æ¥­ç›®æ¨™ã®é”æˆç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["åœ°åŸŸæˆ¦ç•¥", "å–¶æ¥­ç®¡ç†", "ãƒãƒ¼ãƒ çµ±ç‡", "å¸‚å ´é–‹æ‹“"]
        },
        # ãã®ä»–ã®ãƒã‚¸ã‚·ãƒ§ãƒ³å®šç¾©
        "Aäº‹æ¥­éƒ¨ãƒ»å¤§é˜ªæ”¯ç¤¾é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'æ¥­å‹™èƒ½åŠ›': 0.3, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.25, 'å¿ƒèº«å¥å…¨æ€§': 0.15,
                'äººæ ¼ã¨å¿—': 0.15, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.1, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "å¤§é˜ªåœ°åŸŸã«ãŠã‘ã‚‹äº‹æ¥­å±•é–‹ã¨åç›Šç›®æ¨™ã®é”æˆç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["åœ°åŸŸãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ", "åç›Šç®¡ç†", "æ‹ ç‚¹é‹å–¶"]
        },
        "Aäº‹æ¥­éƒ¨ãƒ»æœ¬éƒ¨ãƒ»å–¶æ¥­çµ±æ‹¬éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills if s != 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›'},
            "é‡ã¿": {
                'æ¥­å‹™èƒ½åŠ›': 0.35, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.3, 'å¿ƒèº«å¥å…¨æ€§': 0.15,
                'äººæ ¼ã¨å¿—': 0.1, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.05, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "å…¨äº‹æ¥­éƒ¨ã®å–¶æ¥­æˆ¦ç•¥ç­–å®šã¨å–¶æ¥­éƒ¨éšŠã®çµ±æ‹¬ç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["å–¶æ¥­æˆ¦ç•¥", "è²©å£²ç®¡ç†", "ãƒãƒ¼ãƒ è‚²æˆ"]
        },
        "Aäº‹æ¥­éƒ¨ãƒ»æœ¬éƒ¨ãƒ»æŠ€è¡“çµ±æ‹¬éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'æ¥­å‹™èƒ½åŠ›': 0.4, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.25, 'å¿ƒèº«å¥å…¨æ€§': 0.1,
                'äººæ ¼ã¨å¿—': 0.1, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.1, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "æŠ€è¡“é–‹ç™ºæˆ¦ç•¥ã®ç­–å®šã¨æŠ€è¡“éƒ¨é–€ã®ç·åˆç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["æŠ€è¡“é–‹ç™º", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³", "ç ”ç©¶ç®¡ç†"]
        },
        "Aäº‹æ¥­éƒ¨ãƒ»æœ¬éƒ¨ãƒ»æµ·å¤–çµ±æ‹¬éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.3, 'æ¥­å‹™èƒ½åŠ›': 0.25, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.2,
                'å¿ƒèº«å¥å…¨æ€§': 0.1, 'äººæ ¼ã¨å¿—': 0.1, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "æµ·å¤–äº‹æ¥­ã®å±•é–‹æˆ¦ç•¥ç­–å®šã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«äº‹æ¥­ã®çµ±æ‹¬",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["ã‚°ãƒ­ãƒ¼ãƒãƒ«æˆ¦ç•¥", "ç•°æ–‡åŒ–å¯¾å¿œ", "æµ·å¤–å±•é–‹"]
        },
        "Bäº‹æ¥­éƒ¨ãƒ»å–¶æ¥­çµ±æ‹¬éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'æ¥­å‹™èƒ½åŠ›': 0.35, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.3, 'å¿ƒèº«å¥å…¨æ€§': 0.15,
                'äººæ ¼ã¨å¿—': 0.1, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.05, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "Bäº‹æ¥­éƒ¨å…¨ä½“ã®å–¶æ¥­æˆ¦ç•¥ç­–å®šã¨å–¶æ¥­ç›®æ¨™ã®é”æˆç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["å–¶æ¥­æˆ¦ç•¥", "é¡§å®¢ç®¡ç†", "è²©å£²ä¿ƒé€²"]
        },
        "Bäº‹æ¥­éƒ¨ãƒ»æŠ€è¡“çµ±æ‹¬éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'æ¥­å‹™èƒ½åŠ›': 0.4, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.25, 'å¿ƒèº«å¥å…¨æ€§': 0.1,
                'äººæ ¼ã¨å¿—': 0.1, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.1, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "Bäº‹æ¥­éƒ¨ã®æŠ€è¡“é–‹ç™ºæˆ¦ç•¥ã¨æŠ€è¡“ãƒãƒ¼ãƒ ã®ç·åˆç®¡ç†",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["æŠ€è¡“ç®¡ç†", "é–‹ç™ºæˆ¦ç•¥", "å“è³ªç®¡ç†"]
        },
        "Bäº‹æ¥­éƒ¨ãƒ»é–‹ç™ºçµ±æ‹¬éƒ¨é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'æ¥­å‹™èƒ½åŠ›': 0.45, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.25, 'å¿ƒèº«å¥å…¨æ€§': 0.1,
                'äººæ ¼ã¨å¿—': 0.1, 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.05, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "æ–°è£½å“é–‹ç™ºæˆ¦ç•¥ã®ç­–å®šã¨é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹ã®æœ€é©åŒ–",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["è£½å“é–‹ç™º", "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç®¡ç†", "ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³"]
        },
        "æµ·å¤–å­ä¼šç¤¾é•·": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.3, 'æ¥­å‹™èƒ½åŠ›': 0.25, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.2,
                'å¿ƒèº«å¥å…¨æ€§': 0.15, 'äººæ ¼ã¨å¿—': 0.1, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "æµ·å¤–å­ä¼šç¤¾ã®çµŒå–¶ç®¡ç†ã¨ç¾åœ°æˆ¦ç•¥ã®å®Ÿè¡Œçµ±æ‹¬",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["ã‚°ãƒ­ãƒ¼ãƒãƒ«çµŒå–¶", "ç¾åœ°é©å¿œ", "æµ·å¤–æ‹ ç‚¹ç®¡ç†"]
        },
        "å‹‰å¼·åŠ›è€…": {
            "å¿…é ˆã‚¹ã‚­ãƒ«": {s: 4 for s in skills},
            "é‡ã¿": {
                'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': 0.3, 'æ¥­å‹™èƒ½åŠ›': 0.25, 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': 0.2,
                'å¿ƒèº«å¥å…¨æ€§': 0.15, 'äººæ ¼ã¨å¿—': 0.1, 'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': 0.05
            },
            "éšå±¤": 3,
            "èª¬æ˜": "æ–°ã—ã„æŠ€è¡“ã‚„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’å­¦ã³ã€ãã‚Œã«å¿œç”¨ã—ãŸçµŒå–¶æˆ¦ç•¥",
            "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": ["å­¦ç¿’", "æ–°ã—ã„æŠ€è¡“", "ãƒ“ã‚¸ãƒ§ãƒ³"]
        }
    }

    # å¼·åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆæ–°ã—ã„ã‚¹ã‚­ãƒ«ä½“ç³»ã«åˆã‚ã›ã¦æ›´æ–°ï¼‰
    feedback_library = {
        'å¿ƒèº«å¥å…¨æ€§': [
            "å¹´é–“ã‚’é€šã˜ã¦ç—…æ°—ä¼‘æš‡ã‚’1æ—¥ã‚‚å–å¾—ã›ãšã€é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¶­æŒ",
            "ã‚¹ãƒˆãƒ¬ã‚¹ãƒ•ãƒ«ãªç’°å¢ƒä¸‹ã§ã‚‚å¸¸ã«å†·é™ã•ã‚’ä¿ã¡ã€ãƒãƒ¼ãƒ ã‚’å®‰å®šã•ã›ãŸ",
            "å¥åº·ç®¡ç†ã‚’å¾¹åº•ã—ã€ç¤¾å†…ãƒãƒ©ã‚½ãƒ³å¤§ä¼šã§å„ªå‹ã™ã‚‹ãªã©ä½“åŠ›é¢ã§ã‚‚å„ªã‚Œã‚‹",
            "ãƒ¯ãƒ¼ã‚¯ãƒ©ã‚¤ãƒ•ãƒãƒ©ãƒ³ã‚¹ã‚’å®Ÿè·µã—ã€ç”Ÿç”£æ€§ã®é«˜ã„åƒãæ–¹ã‚’æ¨¡ç¯„ã¨ã—ã¦ç¤ºã—ãŸ"
        ],
        'äººæ ¼ã¨å¿—': [
            "ç§åˆ©ç§æ¬²ãªãä¼šç¤¾ã®ç™ºå±•ã«å°½ãã™å§¿å‹¢ãŒå…¨ç¤¾å“¡ã‹ã‚‰å°Šæ•¬ã•ã‚Œã¦ã„ã‚‹",
            "ç¤¾ä¼šè²¢çŒ®ã¸ã®å¼·ã„å¿—ã‚’æŒã¡ã€CSRæ´»å‹•ã‚’ç©æ¥µçš„ã«æ¨é€²ã—ã¦ã„ã‚‹",
            "å¸¸ã«å…¬å¹³ãªç«‹å ´ã§ç‰©äº‹ã‚’åˆ¤æ–­ã—ã€èª°ã‹ã‚‰ã‚‚ä¿¡é ¼ã•ã‚Œã‚‹äººç‰©",
            "10å¹´å¾Œã®ã‚ã‚‹ã¹ãå§¿ã‚’æ˜ç¢ºã«èªã‚Šã€å‘¨å›²ã‚’é¼“èˆã™ã‚‹åŠ›ãŒã‚ã‚‹"
        ],
        'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': [
            "ã€é¡§å®¢ç¬¬ä¸€ã€ã®ä¿¡å¿µã‚’è²«ãã€é›£ã—ã„å±€é¢ã§ã‚‚å€«ç†è¦³ã‚’å …æŒã—ãŸ",
            "ä¼šç¤¾ã®ã‚³ã‚¢ãƒãƒªãƒ¥ãƒ¼ã‚’ä½“ç¾ã—ã€æ–°å…¥ç¤¾å“¡ã®ãƒ­ãƒ¼ãƒ«ãƒ¢ãƒ‡ãƒ«ã¨ãªã£ã¦ã„ã‚‹",
            "ä¸ç¢ºå®ŸãªçŠ¶æ³ã§ã‚‚ãƒ–ãƒ¬ãªã„åˆ¤æ–­åŸºæº–ã‚’æŒã¡ã€ä¸€è²«ã—ãŸè¡Œå‹•ã‚’å–ã‚‹",
            "ãƒ€ã‚¤ãƒãƒ¼ã‚·ãƒ†ã‚£&ã‚¤ãƒ³ã‚¯ãƒ«ãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å®Ÿè·µã—ã€å¤šæ§˜ãªäººæã‚’æ´»ã‹ã™"
        ],
        'æ¥­å‹™èƒ½åŠ›': [
            "æ‹…å½“æ¥­å‹™ã§å¸¸ã«é«˜ã„æˆæœã‚’ä¸Šã’ã€éƒ¨é–€ã®ç›®æ¨™é”æˆã«å¤§ããè²¢çŒ®",
            "è¤‡é›‘ãªæ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ”¹å–„ã—ã€éƒ¨é–€å…¨ä½“ã®åŠ¹ç‡ã‚’30%å‘ä¸Šã•ã›ãŸ",
            "å°‚é–€åˆ†é‡ã®æ·±ã„çŸ¥è­˜ã‚’æŒã¡ã€å›°é›£ãªèª²é¡Œè§£æ±ºã«ç¹°ã‚Šè¿”ã—æˆåŠŸ",
            "æ–°ã—ã„æ¥­å‹™ã«ã‚‚è¿…é€Ÿã«é©å¿œã—ã€çŸ­æœŸé–“ã§ç”Ÿç”£æ€§ã®é«˜ã„ãƒ¡ãƒ³ãƒãƒ¼ã¨ãªã£ãŸ"
        ],
        'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': [
            "è²¡å‹™è«¸è¡¨ã‚’æ·±ãç†è§£ã—ã€é©åˆ‡ãªè³‡æºé…åˆ†ã‚’ææ¡ˆã—ã¦åç›Šã‚’æ”¹å–„",
            "çµŒå–¶é™£ãƒ¬ãƒ™ãƒ«ã®æ„æ€æ±ºå®šã«å‚åŠ ã—ã€å»ºè¨­çš„ãªæ„è¦‹ã‚’æä¾›ã—ã¦ã„ã‚‹",
            "M&Aæ¡ˆä»¶ã®è©•ä¾¡ã‚’æ‹…å½“ã—ã€é©åˆ‡ãªä¼æ¥­ä¾¡å€¤ç®—å®šã‚’è¡Œã£ãŸ",
            "çµŒå–¶æˆ¦ç•¥ã‚’å®Ÿè¡Œã«ç§»ã™éš›ã®å…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒ³ä½œæˆãŒå¾—æ„"
        ],
        'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': [
            "éå»5å¹´é–“ã§3ã¤ã®ç•°ãªã‚‹éƒ¨é–€ã‚’çµŒé¨“ã—ã€ãã‚Œãã‚Œã§å®Ÿç¸¾ã‚’æ®‹ã—ãŸ",
            "æ–°è¦äº‹æ¥­ç«‹ã¡ä¸Šã’ã‚’æˆåŠŸã•ã›ã€3å¹´ã§å£²ä¸Š10å„„å††ã‚’é”æˆ",
            "æµ·å¤–èµ´ä»»çµŒé¨“ãŒã‚ã‚Šã€å›½éš›ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒªãƒ¼ãƒ‰ã—ãŸå®Ÿç¸¾ãŒã‚ã‚‹",
            "æ¥­ç•Œå›£ä½“ã®å§”å“¡ã‚’å‹™ã‚ã€ç¤¾å¤–ã§ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒåºƒã„"
        ],
        'æ½œåœ¨èƒ½åŠ›': [
            "ã¾ã ä¸€éƒ¨ã—ã‹ç™ºæ®ã•ã‚Œã¦ã„ãªã„ãŒã€é©åˆ‡ãªæŒ‡å°ãŒã‚ã‚Œã°é£›èºçš„ã«æˆé•·ã™ã‚‹å¯èƒ½æ€§ã‚’æ„Ÿã˜ã‚‹",
            "æ–°ã—ã„æ¥­å‹™ã«ã‚‚ã™ãã«é©å¿œã—ã€çŸ­æœŸé–“ã§ç”Ÿç”£æ€§ã®é«˜ã„ãƒ¡ãƒ³ãƒãƒ¼ã¨ãªã£ãŸ",
            "å›°é›£ãªèª²é¡Œã«ç›´é¢ã—ãŸæ™‚ã«è¦‹ã›ã‚‹ç²˜ã‚Šå¼·ã•ã¯ä¸¦å¤–ã‚Œã¦ã„ã‚‹",
            "è‡ªå·±å­¦ç¿’èƒ½åŠ›ãŒé«˜ãã€æ¥­å‹™å¤–ã§ã‚‚é–¢é€£ã™ã‚‹è³‡æ ¼å–å¾—ã‚’ç©æ¥µçš„ã«è¡Œã£ã¦ã„ã‚‹"
        ],
        'æ¥­ç¸¾': [
            "XXãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§äºˆç®—ã‚’15%å‰Šæ¸›ã—ãªãŒã‚‰ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‰å€’ã—ã§å®Œäº†ã•ã›ãŸ",
            "æ–°è¦é¡§å®¢é–‹æ‹“ã«ãŠã„ã¦ã€ç‹¬è‡ªã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§å¹´é–“å£²ä¸Šã‚’25%å¢—åŠ ã•ã›ãŸ",
            "ãƒãƒ¼ãƒ ã®ç”Ÿç”£æ€§å‘ä¸Šæ–½ç­–ã‚’å°å…¥ã—ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆé‚è¡ŒæœŸé–“ã‚’å¹³å‡30%çŸ­ç¸®"
        ],
        'æˆé•·': [
            "å…¥ç¤¾3å¹´ç›®ã«ã—ã¦æ—¢ã«å¾Œè¼©ç¤¾å“¡5åã®ãƒ¡ãƒ³ã‚¿ãƒ¼ã‚’å‹™ã‚ã¦ã„ã‚‹",
            "è‹¦æ‰‹ã ã£ãŸãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚­ãƒ«ã‚’é›†ä¸­çš„ã«æ”¹å–„ã—ã€ç¾åœ¨ã§ã¯ç¤¾å†…ã‚³ãƒ³ãƒ†ã‚¹ãƒˆã§å„ªå‹ã™ã‚‹ã¾ã§ã«æˆé•·",
            "è‹±èªåŠ›ã«èª²é¡ŒãŒã‚ã£ãŸãŒã€è‡ªä¸»å­¦ç¿’ã§TOEICã‚¹ã‚³ã‚¢ã‚’300ç‚¹ä¸Šã’å›½éš›ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å‚ç”»"
        ]
    }

    # 150åã®å¾“æ¥­å“¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    data = []
    departments = ['å–¶æ¥­', 'é–‹ç™º', 'ç”Ÿç”£', 'äººäº‹', 'çµŒå–¶ä¼ç”»']

    for i in range(150):
        dept = np.random.choice(departments)
        emp = {
            'ID': f'E{i + 1:03d}',
            'æ°å': f'å¾“æ¥­å“¡{i + 1}',
            'å¹´é½¢': np.random.randint(30, 56),
            'éƒ¨ç½²': dept,
            'çµŒé¨“å¹´æ•°': np.random.randint(3, 26),
            'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹': np.clip(np.random.normal(3.8, 0.8), 1, 5),
            'æ½œåœ¨åŠ›': np.clip(np.random.normal(0.7, 0.15), 0.3, 1.0),
            'æˆé•·æ„æ¬²': np.clip(np.random.normal(0.8, 0.1), 0.5, 1.0),
            'æ€§æ ¼ç‰¹æ€§': random.choice(['æ…é‡', 'ç©æ¥µçš„', 'å”èª¿æ€§', 'åˆ†æçš„', 'å‰µé€ çš„', 'æƒ…ç†±çš„', 'å†·é™', 'æŒ‘æˆ¦çš„'])
        }

        # æ–°ã—ã„ã‚¹ã‚­ãƒ«ä½“ç³»ã«åŸºã¥ãè©•ä¾¡
        for skill in skills:
            base = np.random.normal(3.8, 0.8) * (0.7 + emp['æ½œåœ¨åŠ›'] * 0.5)
            if dept == 'çµŒå–¶ä¼ç”»' and skill in ['çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›', 'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ']:
                base += 1.5
            elif dept == 'å–¶æ¥­' and skill in ['æ¥­å‹™èƒ½åŠ›', 'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾']:
                base += 1.0
            elif dept == 'é–‹ç™º' and skill in ['æ¥­å‹™èƒ½åŠ›', 'å¿ƒèº«å¥å…¨æ€§']:
                base += 0.7
            emp[skill] = np.clip(base, 1, 5)

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆï¼ˆæ–°ã—ã„ã‚¹ã‚­ãƒ«ä½“ç³»ã«åˆã‚ã›ã¦æ›´æ–°ï¼‰
        feedback_parts = []

        # 1. ã‚¹ã‚­ãƒ«ã«åŸºã¥ãã‚³ãƒ¡ãƒ³ãƒˆï¼ˆå¼·ã¿ã‚¹ã‚­ãƒ«ã‹ã‚‰2ä»¶é¸æŠï¼‰
        strong_skills = [s for s in skills if emp[s] >= 4]
        if len(strong_skills) >= 2:
            selected_skills = np.random.choice(strong_skills, 2, replace=False)
            for skill in selected_skills:
                feedback_parts.append(random.choice(feedback_library[skill]))

        # 2. æ½œåœ¨èƒ½åŠ›ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆç¢ºç‡60%ã§è¿½åŠ ï¼‰
        if random.random() < 0.6:
            feedback_parts.append(random.choice(feedback_library['æ½œåœ¨èƒ½åŠ›']))

        # 3. æ€§æ ¼ç‰¹æ€§ã‚³ãƒ¡ãƒ³ãƒˆ
        feedback_parts.append(f"æ€§æ ¼ç‰¹æ€§: {emp['æ€§æ ¼ç‰¹æ€§']}ã§ã€{random.choice(feedback_library['äººæ ¼ã¨å¿—'])}")

        # 4. æ¥­ç¸¾ã¾ãŸã¯æˆé•·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼ˆã©ã¡ã‚‰ã‹1ä»¶è¿½åŠ ï¼‰
        feedback_parts.append(random.choice([
            "ã€å®Ÿç¸¾ã€‘" + random.choice(feedback_library['æ¥­ç¸¾']),
            "ã€æˆé•·ã€‘" + random.choice(feedback_library['æˆé•·'])
        ]))

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ä¸¦ã³æ›¿ãˆ
        random.shuffle(feedback_parts)
        emp['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯'] = "â–  " + "\nâ–  ".join(feedback_parts)
        data.append(emp)

        # ã‚¹ã‚­ãƒ«ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã®æ¤œè¨¼
        print("ç”Ÿæˆã•ã‚ŒãŸã‚¹ã‚­ãƒ«å€¤ã®çµ±è¨ˆ:")
        for skill in skills:
            values = [emp[skill] for emp in data]
            # print(f"{skill}: å¹³å‡={np.mean(values):.2f} æœ€å¤§={np.max(values):.2f} æœ€å°={np.min(values):.2f}")

    # æŠŠdataå†™å…¥åˆ°excelæ–‡ä»¶ä¸­
    df = pd.DataFrame(data)
    df.to_excel('data.xlsx', index=False)

    return pd.DataFrame(data), skills, position_requirements


# 2. æ¨è–¦ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆæ–°ã—ã„ã‚¹ã‚­ãƒ«ä½“ç³»ã«å¯¾å¿œï¼‰
class SuccessionPlanner:
    def __init__(self, df, skills, position_reqs):
        self.df = df
        self.skills = skills
        self.position_reqs = position_reqs

        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®åˆæœŸåŒ–
        self.scalers = {
            'skill': MinMaxScaler().fit(df[skills]),
            'performance': MinMaxScaler().fit(df[['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹']])
        }

        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã®è¨­å®š
        self.vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),
            max_features=500,
            stop_words=['ãŒ', 'ã‚’', 'ã«', 'ã®', 'ã¯', 'ã§', 'ãŸ'],
            token_pattern=r'(?u)\b\w+\b'
        )
        self.tfidf_matrix = self.vectorizer.fit_transform(df['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯'])

        # ã‚¹ã‚­ãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ—
        self.skill_keywords = {
            'å¿ƒèº«å¥å…¨æ€§': ['å¥åº·', 'ä½“åŠ›', 'ã‚¹ãƒˆãƒ¬ã‚¹', 'å¿è€', 'æŒä¹…åŠ›', 'ãƒ¡ãƒ³ã‚¿ãƒ«'],
            'äººæ ¼ã¨å¿—': ['äººæ ¼', 'å¿—', 'ä¿¡å¿µ', 'å€«ç†', 'ç†å¿µ', 'ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—'],
            'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': ['ä¾¡å€¤è¦³', 'ä¿¡å¿µ', 'å€«ç†', 'åˆ¤æ–­', 'åŸºæº–', 'å“²å­¦'],
            'æ¥­å‹™èƒ½åŠ›': ['æ¥­å‹™', 'åŠ¹ç‡', 'ç”Ÿç”£æ€§', 'å°‚é–€', 'é‚è¡Œ', 'ã‚¹ã‚­ãƒ«'],
            'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': ['çµŒå–¶', 'è²¡å‹™', 'æˆ¦ç•¥', 'æ„æ€æ±ºå®š', 'M&A', 'ã‚¬ãƒãƒŠãƒ³ã‚¹'],
            'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': ['å®Ÿç¸¾', 'çµŒé¨“', 'ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ', 'æˆæœ', 'ã‚­ãƒ£ãƒªã‚¢', 'å®Ÿå‹™']
        }

        # è‚²æˆè¨ˆç”»
        self.development_plans = {
            'å¿ƒèº«å¥å…¨æ€§': [
                "å¥åº·ç®¡ç†ãƒ—ãƒ­ã‚°ãƒ©ãƒ (6ãƒ¶æœˆ)",
                "ã‚¹ãƒˆãƒ¬ã‚¹ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆç ”ä¿®",
                "ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°"
            ],
            'äººæ ¼ã¨å¿—': [
                "ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—å“²å­¦ç ”ä¿®",
                "çµŒå–¶è€…ãƒ¡ãƒ³ã‚¿ãƒªãƒ³ã‚°ãƒ—ãƒ­ã‚°ãƒ©ãƒ ",
                "ç¤¾ä¼šè²¢çŒ®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒªãƒ¼ãƒ€ãƒ¼çµŒé¨“"
            ],
            'ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µ': [
                "ä¼æ¥­ç†å¿µæ·±åŒ–ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ§ãƒƒãƒ—",
                "ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–å€«ç†ç ”ä¿®",
                "ãƒ€ã‚¤ãƒãƒ¼ã‚·ãƒ†ã‚£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°"
            ],
            'æ¥­å‹™èƒ½åŠ›': [
                "å°‚é–€åˆ†é‡ã‚¢ãƒ‰ãƒãƒ³ã‚¹ãƒˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°",
                "æ¥­å‹™ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
                "ä»–éƒ¨é–€ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"
            ],
            'çµŒå–¶å®Ÿå‹™ã®çŸ¥è­˜ã¨ç™ºæ®èƒ½åŠ›': [
                "çµŒå–¶ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ­ã‚°ãƒ©ãƒ ",
                "è²¡å‹™åˆ†æã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆé¤Šæˆè¬›åº§",
                "å½¹å“¡ä¼šã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ¼çµŒé¨“"
            ],
            'è·å‹™çµŒæ­´ãƒ»å®Ÿç¸¾': [
                "ç¤¾å†…å…¬å‹Ÿãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®å‚åŠ ",
                "æµ·å¤–æ´¾é£ãƒ—ãƒ­ã‚°ãƒ©ãƒ ",
                "æ–°è¦äº‹æ¥­ç«‹ã¡ä¸Šã’ã‚¿ã‚¹ã‚¯ãƒ•ã‚©ãƒ¼ã‚¹"
            ]
        }

    @functools.lru_cache(maxsize=32)
    def get_text_similarity(self, position):
        """ãƒ†ã‚­ã‚¹ãƒˆé¡ä¼¼åº¦è¨ˆç®—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
        reqs = self.position_reqs[position]
        pos_keywords = " ".join(reqs.get("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", []))
        pos_vector = self.vectorizer.transform([pos_keywords])
        return cosine_similarity(self.tfidf_matrix, pos_vector)

    def extract_potential(self, feedback):
        """å¼·åŒ–ã•ã‚ŒãŸæ½œåœ¨èƒ½åŠ›æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯"""
        signals = [
            ('å¯èƒ½æ€§', 0.3), ('æ½œåœ¨', 0.3), ('æˆé•·', 0.2),
            ('ä¼¸ã³ã—ã‚', 0.4), ('é©å¿œåŠ›', 0.2), ('æœŸå¾…', 0.3),
            ('é£›èº', 0.4), ('ç´ è³ª', 0.3), ('å°†æ¥æ€§', 0.3)
        ]

        score = 0
        for keyword, weight in signals:
            if keyword in feedback:
                score += weight

        # å…·ä½“çš„äº‹ä¾‹ã®æœ‰ç„¡
        if any(word in feedback for word in ['å®Ÿç¸¾', 'æˆæœ', 'é”æˆ', 'æˆåŠŸ']):
            score += 0.2

        # æˆé•·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰
        if any(word in feedback for word in ['æ”¹å–„', 'å‘ä¸Š', 'ç¿’å¾—', 'æˆé•·']):
            score += 0.2

        return min(1.0, score)

    def recommend_candidates(self, position, top_n=3):
        try:
            reqs = self.position_reqs[position]
            print(f"\n=== {position}ã®æ¨è–¦å‡¦ç†é–‹å§‹ ===")

            # å…¨å€™è£œè€…ã‚’ã‚³ãƒ”ãƒ¼
            candidates_df = self.df.copy()

            # ã‚¹ã‚­ãƒ«ä¸è¶³åº¦ã‚’è¨ˆç®—ï¼ˆå¿…é ˆã‚¹ã‚­ãƒ«ã¨ã®å·®ï¼‰
            skill_shortfalls = []
            for skill, min_level in reqs["å¿…é ˆã‚¹ã‚­ãƒ«"].items():
                candidates_df[f'{skill}_ä¸è¶³'] = np.clip(min_level - 0.5 - candidates_df[skill], 0, None)
                skill_shortfalls.append(f'{skill}_ä¸è¶³')

            # ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢è¨ˆç®—
            skill_weights = np.array([reqs["é‡ã¿"].get(s, 0) for s in self.skills])
            candidates_df['ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢'] = candidates_df[self.skills].values.dot(skill_weights)

            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
            candidates_df['ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢_scaled'] = self.scalers['skill'].transform(candidates_df[self.skills]).mean(
                axis=1)
            candidates_df['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹_scaled'] = self.scalers['performance'].transform(
                candidates_df[['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹']]).flatten()

            # ãƒ†ã‚­ã‚¹ãƒˆãƒãƒƒãƒãƒ³ã‚°ã‚¹ã‚³ã‚¢
            text_sim = self.get_text_similarity(position)
            candidates_df['ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢'] = text_sim[candidates_df.index].flatten()

            # æ½œåœ¨èƒ½åŠ›ã‚¹ã‚³ã‚¢
            candidates_df['æ½œåœ¨ã‚¹ã‚³ã‚¢'] = candidates_df['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯'].apply(self.extract_potential)

            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚¹ã‚­ãƒ«ä¸è¶³ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é©ç”¨ï¼‰
            skill_penalty = candidates_df[skill_shortfalls].sum(axis=1) * 0.1  # ä¸è¶³1ãƒã‚¤ãƒ³ãƒˆã”ã¨ã«10%æ¸›ç‚¹
            candidates_df['ç·åˆã‚¹ã‚³ã‚¢'] = (
                                                  0.4 * candidates_df['ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢_scaled'] +
                                                  0.3 * candidates_df['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹_scaled'] +
                                                  0.2 * candidates_df['ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢'] +
                                                  0.1 * candidates_df['æ½œåœ¨ã‚¹ã‚³ã‚¢']
                                          ) * (1 - skill_penalty)  # ãƒšãƒŠãƒ«ãƒ†ã‚£é©ç”¨

            # æ¨è–¦ç†ç”±ç”Ÿæˆ
            candidates_df['æ¨è–¦ç†ç”±'] = candidates_df.apply(
                lambda x: self.generate_reason(x, position), axis=1)

            # çµæœã‚’æ•´å½¢ã—ã¦è¿”ã™
            # result_cols = ['ID', 'æ°å', 'éƒ¨ç½²'] + self.skills + ['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢',
            #                                                       'ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢', 'æ½œåœ¨ã‚¹ã‚³ã‚¢', 'ç·åˆã‚¹ã‚³ã‚¢',
            #                                                       'æ¨è–¦ç†ç”±']
            # result_df = candidates_df[result_cols].nlargest(top_n, 'ç·åˆã‚¹ã‚³ã‚¢').reset_index(drop=True)
            #
            # print("\næ¨è–¦çµæœãƒˆãƒƒãƒ—3:")
            # print(result_df[['ID', 'ç·åˆã‚¹ã‚³ã‚¢']])
            # return result_df
            result_cols = ['ID', 'æ°å', 'éƒ¨ç½²'] + self.skills + ['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢',
                                                                  'ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢', 'æ½œåœ¨ã‚¹ã‚³ã‚¢', 'ç·åˆã‚¹ã‚³ã‚¢',
                                                                  'æ¨è–¦ç†ç”±',
                                                                  'ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯']
            result_df = candidates_df[result_cols].nlargest(top_n, 'ç·åˆã‚¹ã‚³ã‚¢').reset_index(drop=True)
            return result_df
        except Exception as e:
            print(f"æ¨è–¦å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
            return pd.DataFrame()

    def generate_reason(self, candidate, position):
        reqs = self.position_reqs[position]
        reasons = []

        # ã‚¹ã‚­ãƒ«é©åˆæ€§ï¼ˆä¸è¶³ãƒã‚¤ãƒ³ãƒˆã‚’æ˜ç¤ºï¼‰
        missing_skills = []
        for skill, min_level in reqs["å¿…é ˆã‚¹ã‚­ãƒ«"].items():
            actual = candidate[skill]
            required = min_level - 0.5
            if actual >= required:
                level = "â—" if actual >= 4.5 else "â—‹"
                reasons.append(f"{skill}{level}({actual:.1f}/5)")
            else:
                missing_skills.append(f"{skill}(ä¸è¶³:{required - actual:.1f})")

        if missing_skills:
            reasons.append(f"â€»è¦æ”¹å–„ã‚¹ã‚­ãƒ«: {', '.join(missing_skills)}")

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åˆ†æ
        feedback_analysis = []

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        matched_keywords = []
        for skill in reqs["å¿…é ˆã‚¹ã‚­ãƒ«"]:
            if any(kw in candidate['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯']
                   for kw in self.skill_keywords.get(skill, [])):
                matched_keywords.append(skill)
        if matched_keywords:
            feedback_analysis.append(f"{len(matched_keywords)}ã‚¹ã‚­ãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º")

        # å…·ä½“çš„äº‹ä¾‹
        if any(c in candidate['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯'] for c in ['å®Ÿç¸¾', 'æˆæœ', 'é”æˆ']):
            feedback_analysis.append("å…·ä½“çš„äº‹ä¾‹ã‚ã‚Š")

        # æˆé•·è¨˜éŒ²
        if any(c in candidate['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯'] for c in ['æˆé•·', 'æ”¹å–„', 'å‘ä¸Š']):
            feedback_analysis.append("æˆé•·è¨˜éŒ²ã‚ã‚Š")

        if feedback_analysis:
            reasons.append("å®šæ€§åˆ†æ: " + ", ".join(feedback_analysis))

        # æ½œåœ¨èƒ½åŠ›
        potential_score = self.extract_potential(candidate['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯'])
        if potential_score > 0.6:
            reasons.append(f"æ½œåœ¨èƒ½åŠ›: {potential_score:.0%}")
            reasons.append(f"æˆé•·æ„æ¬²: {candidate['æˆé•·æ„æ¬²']:.1f}/1.0")

        return f"ã€{position}é©æ€§ã€‘\n" + "\n".join(f"ãƒ»{r}" for r in reasons)

    def predict_growth(self, candidate_id, position):
        candidate = self.df[self.df['ID'] == candidate_id].iloc[0]
        reqs = self.position_reqs[position]

        predictions = {
            'year': ['ç¾åœ¨', '1å¹´å¾Œ', '2å¹´å¾Œ', '3å¹´å¾Œ'],
            'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹': [candidate['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹']],
            'ã‚¹ã‚­ãƒ«': {},
            'è‚²æˆè¨ˆç”»': []
        }

        # ã‚¹ã‚­ãƒ«æˆé•·äºˆæ¸¬
        for skill in self.skills:
            current = candidate[skill]
            growth = 0

            if skill in reqs["å¿…é ˆã‚¹ã‚­ãƒ«"]:
                plan = random.choice(self.development_plans[skill])
                predictions['è‚²æˆè¨ˆç”»'].append(f"{skill}: {plan}")
                growth = min(0.7, 0.2 + candidate['æˆé•·æ„æ¬²'] * 0.5)

            predictions['ã‚¹ã‚­ãƒ«'][skill] = [
                current,
                np.clip(current + growth * 0.5, 1, 5),
                np.clip(current + growth * 0.8, 1, 5),
                np.clip(current + growth, 1, 5)
            ]

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
        perf_growth = sum(
            (predictions['ã‚¹ã‚­ãƒ«'][s][-1] - predictions['ã‚¹ã‚­ãƒ«'][s][0]) * w
            for s, w in reqs["é‡ã¿"].items()
        ) / sum(reqs["é‡ã¿"].values())

        predictions['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹'].extend([
            np.clip(candidate['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹'] + perf_growth * 0.3, 1, 5),
            np.clip(candidate['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹'] + perf_growth * 0.6, 1, 5),
            np.clip(candidate['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹'] + perf_growth, 1, 5)
        ])

        return predictions

    # def analyze_optimal_team(self):
    #     """ç¬¬1éšå±¤ã¨ç¬¬2éšå±¤ã®æœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’3æ¡ˆæç¤º"""
    #     with ThreadPoolExecutor() as executor:
    #         candidates = {
    #             pos: executor.submit(self.recommend_candidates, pos, 2).result()['ID'].tolist()
    #             for pos, reqs in self.position_reqs.items() if reqs["éšå±¤"] <= 2
    #         }
    #
    #     president_candidates = candidates.get("ç¤¾é•·", [])
    #     other_positions = [p for p in candidates.keys() if p != "ç¤¾é•·"]
    #
    #     team_options = []
    #     for pres in president_candidates:
    #         for _ in range(3):
    #             team = {
    #                 "ç¤¾é•·": pres,
    #                 "ãƒ¡ãƒ³ãƒãƒ¼": {},
    #                 "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸": 0,
    #                 "å¤šæ§˜æ€§": 0,
    #                 "ãƒªã‚¹ã‚¯": 0,
    #                 "å¼·ã¿": [],
    #                 "å¼±ã¿": []
    #             }
    #
    #             selected = set([pres])
    #             for pos in other_positions:
    #                 available = [c for c in candidates[pos] if c not in selected]
    #                 if available:
    #                     choice = np.random.choice(available)
    #                     team["ãƒ¡ãƒ³ãƒãƒ¼"][pos] = choice
    #                     selected.add(choice)
    #
    #             team_df = self.df[self.df['ID'].isin([pres] + list(team["ãƒ¡ãƒ³ãƒãƒ¼"].values()))]
    #
    #             # ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸
    #             max_skills = team_df[self.skills].max()
    #             team["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"] = max_skills.mean() / 5
    #
    #             # éƒ¨ç½²å¤šæ§˜æ€§
    #             team["å¤šæ§˜æ€§"] = len(team_df['éƒ¨ç½²'].unique()) / len(self.df['éƒ¨ç½²'].unique())
    #
    #             # ãƒªã‚¹ã‚¯è©•ä¾¡
    #             team["ãƒªã‚¹ã‚¯"] = 1 - team_df['æ½œåœ¨åŠ›'].mean()
    #
    #             # å¼·ã¿/å¼±ã¿åˆ†æ
    #             team_skills = team_df[self.skills].mean()
    #             top_skills = team_skills.nlargest(3)
    #             weak_skills = team_skills.nsmallest(2)
    #
    #             team["å¼·ã¿"] = [f"{s}({v:.1f}/5)" for s, v in top_skills.items()]
    #             team["å¼±ã¿"] = [f"{s}({v:.1f}/5)" for s, v in weak_skills.items()]
    #
    #             team_options.append(team)
    #
    #     # ãƒˆãƒƒãƒ—3ãƒãƒ¼ãƒ é¸å‡º
    #     top_teams = sorted(team_options, key=lambda x: (
    #         x["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"],
    #         x["å¤šæ§˜æ€§"],
    #         -x["ãƒªã‚¹ã‚¯"]
    #     ), reverse=True)[:3]
    #
    #     return top_teams
    def analyze_optimal_team(self):
        """ç¬¬1éšå±¤ã¨ç¬¬2éšå±¤ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæœ€é©çµ„ã¿åˆã‚ã›ã‚’3æ¡ˆæç¤º"""
        team_options = []
        used_combinations = set()

        # å€™è£œè€…ãƒ—ãƒ¼ãƒ«ã®ç”Ÿæˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°è¿½åŠ ï¼‰
        print("\n=== ãƒãƒ¼ãƒ ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹ ===")
        print("å€™è£œè€…ãƒ—ãƒ¼ãƒ«ç”Ÿæˆä¸­...")
        with ThreadPoolExecutor() as executor:
            candidate_futures = {
                pos: executor.submit(self.recommend_candidates, pos, 5)
                for pos, reqs in self.position_reqs.items()
                if reqs["éšå±¤"] <= 2
            }
            candidates = {}
            for pos, future in candidate_futures.items():
                try:
                    result = future.result()
                    if not result.empty:
                        candidates[pos] = result['ID'].tolist()
                        print(f"âœ… {pos}: {len(candidates[pos])}åã®å€™è£œè€…ã‚’å–å¾—")
                    else:
                        print(f"âš ï¸ {pos}: å€™è£œè€…ãªã—")
                        candidates[pos] = []
                except Exception as e:
                    print(f"ğŸ”¥ {pos} å€™è£œè€…å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    candidates[pos] = []

        # ç¤¾é•·å€™è£œãƒã‚§ãƒƒã‚¯
        if not candidates.get("ç¤¾é•·"):
            print("ğŸ›‘ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: ç¤¾é•·å€™è£œãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return []

        # print(f"\nç¤¾é•·å€™è£œæ•°: {len(candidates['ç¤¾é•·']}")
        
        print("ãƒãƒ¼ãƒ ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")

        # ãƒãƒ¼ãƒ ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
        max_attempts =100
        attempt_count = 0
        generated_teams = 0

        while generated_teams < 3 and attempt_count < max_attempts:
            attempt_count += 1
            pres = random.choice(candidates["ç¤¾é•·"])
            other_positions = [p for p in candidates.keys() if p != "ç¤¾é•·"]

            team = self._generate_team(pres, candidates, other_positions)
            team_hash = self._create_team_hash(team)

            if team_hash not in used_combinations:
                self._evaluate_team(team)
                team_options.append(team)
                used_combinations.add(team_hash)
                generated_teams += 1
                print(f"ğŸ¯ æ–°è¦ãƒãƒ¼ãƒ ç”Ÿæˆ ({generated_teams}/3) - ãƒãƒƒã‚·ãƒ¥: {team_hash}")

        # ãƒãƒ¼ãƒ è©•ä¾¡ã§ãƒˆãƒƒãƒ—3ã‚’é¸å‡º
        top_teams = sorted(
            team_options,
            key=lambda x: (x["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"], x["å¤šæ§˜æ€§"], -x["ãƒªã‚¹ã‚¯"]),
            reverse=True
        )[:3]

        print("\n=== ãƒãƒ¼ãƒ ç”Ÿæˆçµæœ ===")
        print(f"ç”Ÿæˆãƒãƒ¼ãƒ å€™è£œæ•°: {len(team_options)}")
        print(f"æœ€é©ãƒãƒ¼ãƒ é¸å‡ºæ•°: {len(top_teams)}")

        return self._remove_duplicate_teams(top_teams)

    def _generate_team(self, pres, candidates, other_positions):
        """ãƒãƒ¼ãƒ ç”Ÿæˆãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
        team = {
            "ç¤¾é•·": pres,
            "ãƒ¡ãƒ³ãƒãƒ¼": {},
            "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸": 0,
            "å¤šæ§˜æ€§": 0,
            "ãƒªã‚¹ã‚¯": 0,
            "å¼·ã¿": [],
            "å¼±ã¿": []
        }
        selected = {pres}

        for pos in other_positions:
            available = [c for c in candidates[pos] if c not in selected]
            if available:
                choice = random.choice(available)
                team["ãƒ¡ãƒ³ãƒãƒ¼"][pos] = choice
                selected.add(choice)
                print(f"  â†’ {pos}: {choice} ã‚’è¿½åŠ ")
            else:
                print(f"  â†’ {pos}: é©ä»»å€™è£œãªã—")

        return team

    def _evaluate_team(self, team):
        """ãƒãƒ¼ãƒ è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¼·ã¿/å¼±ã¿åˆ†æå«ã‚€ï¼‰"""
        member_ids = [team["ç¤¾é•·"]] + list(team["ãƒ¡ãƒ³ãƒãƒ¼"].values())
        team_df = self.df[self.df['ID'].isin(member_ids)]

        # ã‚¹ã‚­ãƒ«åˆ†æ
        max_skills = team_df[self.skills].max()
        mean_skills = team_df[self.skills].mean()

        # å¼·ã¿ï¼ˆä¸Šä½3ã‚¹ã‚­ãƒ«ï¼‰
        top_skills = mean_skills.nlargest(3)
        team["å¼·ã¿"] = [
            f"{skill}ï¼ˆå¹³å‡:{value:.1f}/æœ€å¤§:{max_skills[skill]:.1f})"
            for skill, value in top_skills.items()
        ]

        # å¼±ã¿ï¼ˆä¸‹ä½2ã‚¹ã‚­ãƒ«ï¼‰
        weak_skills = mean_skills.nsmallest(2)
        team["å¼±ã¿"] = [
            f"{skill}ï¼ˆå¹³å‡:{value:.1f}/æœ€å¤§:{max_skills[skill]:.1f})"
            for skill, value in weak_skills.items()
        ]

        # æ•°å€¤æŒ‡æ¨™
        team["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"] = max_skills.mean() / 5
        team["å¤šæ§˜æ€§"] = len(team_df['éƒ¨ç½²'].unique()) / len(self.df['éƒ¨ç½²'].unique())
        team["ãƒªã‚¹ã‚¯"] = 1 - team_df['æ½œåœ¨åŠ›'].mean()

    def _create_team_hash(self, team):
        """ãƒãƒ¼ãƒ ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ"""
        members = tuple(sorted([team["ç¤¾é•·"]] + list(team["ãƒ¡ãƒ³ãƒãƒ¼"].values())))
        return hash(members)

    def _remove_duplicate_teams(self, teams):
        """é‡è¤‡ãƒãƒ¼ãƒ æ’é™¤"""
        seen = set()
        unique = []
        for team in teams:
            team_hash = self._create_team_hash(team)
            if team_hash not in seen:
                seen.add(team_hash)
                unique.append(team)
        return unique
    # def analyze_optimal_team(self):
    #     """ç¬¬1éšå±¤ã¨ç¬¬2éšå±¤ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæœ€é©çµ„ã¿åˆã‚ã›ã‚’3æ¡ˆæç¤º"""
    #     used_combinations = set()
    #     team_options = []
    #     # å€™è£œè€…ãƒ—ãƒ¼ãƒ«ã®ç”Ÿæˆï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
    #     with ThreadPoolExecutor() as executor:
    #         candidate_futures = {
    #             pos: executor.submit(self.recommend_candidates, pos, 5)
    #             for pos, reqs in self.position_reqs.items()
    #             if reqs["éšå±¤"] <= 2
    #         }
    #         candidates = {
    #             pos: future.result()['ID'].tolist()
    #             for pos, future in candidate_futures.items()
    #         }
    #     # ç¤¾é•·å€™è£œã”ã¨ã«æœ€å¤§5ãƒãƒ¼ãƒ ç”Ÿæˆ
    #     for pres in candidates.get("ç¤¾é•·", []):
    #         team_count = 0
    #         other_positions = [p for p in candidates.keys() if p != "ç¤¾é•·"]
    #         while team_count < 5 and len(team_options) < 15:
    #             team = self._generate_team(pres, candidates, other_positions)
    #             team_hash = self._create_team_hash(team)
    #             if team_hash not in used_combinations:
    #                 self._evaluate_team(team)
    #                 team_options.append(team)
    #                 used_combinations.add(team_hash)
    #                 team_count += 1
    #     # ãƒãƒ¼ãƒ è©•ä¾¡ã§ãƒˆãƒƒãƒ—3ã‚’é¸å‡º
    #     top_teams = sorted(
    #         team_options,
    #         key=lambda x: (x["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"], x["å¤šæ§˜æ€§"], -x["ãƒªã‚¹ã‚¯"]),
    #         reverse=True
    #     )[:3]
    #     return self._remove_duplicate_teams(top_teams)
    # def _generate_team(self, pres, candidates, other_positions):
    #     """ãƒãƒ¼ãƒ ç”Ÿæˆã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    #     team = {
    #         "ç¤¾é•·": pres,
    #         "ãƒ¡ãƒ³ãƒãƒ¼": {},
    #         "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸": 0,
    #         "å¤šæ§˜æ€§": 0,
    #         "ãƒªã‚¹ã‚¯": 0,
    #         "å¼·ã¿": [],
    #         "å¼±ã¿": []
    #     }
    #     selected = {pres}
    #     for pos in other_positions:
    #         available = [c for c in candidates[pos] if c not in selected]
    #         if available:
    #             choice = self._select_unique_candidate(available, selected)
    #             team["ãƒ¡ãƒ³ãƒãƒ¼"][pos] = choice
    #             selected.add(choice)
    #     return team
    # def _select_unique_candidate(self, candidates, used_set):
    #     """é‡è¤‡ã—ãªã„å€™è£œè€…é¸æŠ"""
    #     for candidate in candidates:
    #         if candidate not in used_set:
    #             return candidate
    #     return None
    # # def _evaluate_team(self, team):
    # #     """ãƒãƒ¼ãƒ è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯"""
    # #     team_df = self.df[self.df['ID'].isin([team["ç¤¾é•·"]] + list(team["ãƒ¡ãƒ³ãƒãƒ¼"].values()))]
    # #     team["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"] = team_df[self.skills].max().mean() / 5
    # #     team["å¤šæ§˜æ€§"] = len(team_df['éƒ¨ç½²'].unique()) / len(self.df['éƒ¨ç½²'].unique())
    # #     team["ãƒªã‚¹ã‚¯"] = 1 - team_df['æ½œåœ¨åŠ›'].mean()
    # #     team_skills = team_df[self.skills].mean()
    # #     team["å¼·ã¿"] = [f"{s}({v:.1f}/5)" for s, v in team_skills.nlargest(3).items()]
    # #     team["å¼±ã¿"] = [f"{s}({v:.1f}/5)" for s, v in team_skills.nsmallest(2).items()]
    # def _evaluate_team(self, team):
    #     """ãƒãƒ¼ãƒ è©•ä¾¡ãƒ­ã‚¸ãƒƒã‚¯"""
    #     members = [team["ç¤¾é•·"]] + list(team.get("ãƒ¡ãƒ³ãƒãƒ¼", {}).values())
    #     members = [m for m in members if m is not None]
    #
    #     team_df = self.df[self.df['ID'].isin(members)]
    #
    #     if team_df.empty:
    #         # ãƒ¡ãƒ³ãƒãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    #         team["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"] = 0
    #         team["å¤šæ§˜æ€§"] = 0
    #         team["ãƒªã‚¹ã‚¯"] = 1
    #         team["å¼·ã¿"] = []
    #         team["å¼±ã¿"] = []
    #         return
    #
    #     team["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"] = team_df[self.skills].max().mean() / 5
    #
    #     total_departments = len(self.df['éƒ¨ç½²'].unique())
    #     team["å¤šæ§˜æ€§"] = len(team_df['éƒ¨ç½²'].unique()) / total_departments if total_departments > 0 else 0
    #
    #     team["ãƒªã‚¹ã‚¯"] = 1 - team_df['æ½œåœ¨åŠ›'].mean()
    #
    #     team_skills = team_df[self.skills].mean()
    #     team["å¼·ã¿"] = [f"{s}({v:.1f}/5)" for s, v in team_skills.nlargest(3).items()]
    #     team["å¼±ã¿"] = [f"{s}({v:.1f}/5)" for s, v in team_skills.nsmallest(2).items()]
    #
    # def _create_team_hash(self, team):
    #     """ãƒãƒ¼ãƒ ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ"""
    #     members = tuple(sorted([team["ç¤¾é•·"]] + list(team["ãƒ¡ãƒ³ãƒãƒ¼"].values())))
    #     return hash(members)
    # def _remove_duplicate_teams(self, teams):
    #     """å®Œå…¨é‡è¤‡ãƒãƒ¼ãƒ ã®æ’é™¤"""
    #     seen = set()
    #     unique_teams = []
    #     for team in teams:
    #         team_hash = self._create_team_hash(team)
    #         if team_hash not in seen:
    #             seen.add(team_hash)
    #             unique_teams.append(team)
    #     return unique_teams[:3]

# 3. å¯è¦–åŒ–é–¢æ•°
def plot_growth(predictions, position):
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
    fig_perf = go.Figure()
    fig_perf.add_trace(go.Scatter(
        x=predictions['year'],
        y=predictions['ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹'],
        name='ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹',
        line=dict(width=4, color='#1f77b4'),
        marker=dict(size=10)
    ))
    fig_perf.update_layout(
        title=f'{position}ã¨ã—ã¦ã®æˆé•·äºˆæ¸¬',
        yaxis=dict(range=[1, 5], title='ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡'),
        xaxis=dict(title='å¹´åº¦'),
        template='plotly_white'
    )

    # ã‚¹ã‚­ãƒ«äºˆæ¸¬
    fig_skill = go.Figure()
    for skill, values in predictions['ã‚¹ã‚­ãƒ«'].items():
        fig_skill.add_trace(go.Scatter(
            x=predictions['year'],
            y=values,
            name=skill,
            mode='lines+markers'
        ))
    fig_skill.update_layout(
        title='ã‚¹ã‚­ãƒ«é€²åŒ–äºˆæ¸¬',
        yaxis=dict(range=[1, 5], title='ã‚¹ã‚­ãƒ«ãƒ¬ãƒ™ãƒ«'),
        xaxis=dict(title='å¹´åº¦'),
        template='plotly_white'
    )

    return fig_perf, fig_skill


def display_team_analysis(planner, team, df):
    pres = df[df['ID'] == team["ç¤¾é•·"]].iloc[0]
    members = {pos: df[df['ID'] == eid].iloc[0] for pos, eid in team["ãƒ¡ãƒ³ãƒãƒ¼"].items()}

    st.markdown(f"""
    ## ãƒãƒ¼ãƒ æ¡ˆã®ç‰¹å¾´
    **ç¤¾é•·å€™è£œ**: {pres['æ°å']} ({pres['éƒ¨ç½²']})  
    **ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸**: {team["ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"]:.0%}  
    **éƒ¨ç½²å¤šæ§˜æ€§**: {team["å¤šæ§˜æ€§"]:.0%}  
    **ãƒªã‚¹ã‚¯è©•ä¾¡**: {'ä½' if team["ãƒªã‚¹ã‚¯"] < 0.3 else 'ä¸­' if team["ãƒªã‚¹ã‚¯"] < 0.6 else 'é«˜'}
    """)

    # ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼è¡¨
    member_data = []
    # for pos, member in members.items():
    #     print("#"*100)
    #     print(member[planner.skills])
    #     print("#"*100)
    #
    #     member_data.append({
    #         "ãƒã‚¸ã‚·ãƒ§ãƒ³": pos,
    #         "æ°å": member['æ°å'],
    #         "éƒ¨ç½²": member['éƒ¨ç½²'],
    #         "ä¸»è¦ã‚¹ã‚­ãƒ«": ", ".join(member[planner.skills].nlargest(3).index.tolist()),
    #         "ç·åˆã‚¹ã‚³ã‚¢": f"{planner.recommend_candidates(pos, top_n=10).set_index('ID').loc[member['ID'], 'ç·åˆã‚¹ã‚³ã‚¢']:.2f}"
    #     })
    # st.table(pd.DataFrame(member_data))
    for pos, member in members.items():
        # ã‚¹ã‚­ãƒ«ãŒæ•°å€¤ãƒ‡ãƒ¼ã‚¿å‹ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        skills = member[planner.skills].astype(float)

        member_data.append({
            "ãƒã‚¸ã‚·ãƒ§ãƒ³": pos,
            "æ°å": member['æ°å'],
            "éƒ¨ç½²": member['éƒ¨ç½²'],
            "ä¸»è¦ã‚¹ã‚­ãƒ«": ", ".join(skills.nlargest(3).index.tolist()),
            "ç·åˆã‚¹ã‚³ã‚¢": f"{planner.recommend_candidates(pos, top_n=10).set_index('ID').loc[member['ID'], 'ç·åˆã‚¹ã‚³ã‚¢']:.2f}"
        })
    st.table(pd.DataFrame(member_data))

    # å¼·ã¿ã¨å¼±ã¿
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### ãƒãƒ¼ãƒ ã®å¼·ã¿")
        for strength in team["å¼·ã¿"]:
            st.markdown(f"- {strength}")
    with col2:
        st.markdown("### æ”¹å–„ç‚¹")
        for weakness in team["å¼±ã¿"]:
            st.markdown(f"- {weakness}")

    # æ¨å¥¨ç†ç”±
    st.markdown("""
    ### æ¨å¥¨ç†ç”±
    ã“ã®ãƒãƒ¼ãƒ ç·¨æˆã¯ä»¥ä¸‹ã®ç‚¹ã§å„ªã‚Œã¦ã„ã¾ã™:
    - å¿…è¦ãªã‚¹ã‚­ãƒ«ã‚’åºƒç¯„å›²ã«ã‚«ãƒãƒ¼
    - è¤‡æ•°ã®éƒ¨ç½²ã‹ã‚‰äººæã‚’é¸å‡ºã—å¤šæ§˜æ€§ã‚’ç¢ºä¿
    - å¹³å‡æ½œåœ¨åŠ›ãŒé«˜ãä»Šå¾Œã®æˆé•·ãŒè¦‹è¾¼ã‚ã‚‹
    """)

    # ãƒªã‚¹ã‚¯è¦å› 
    st.markdown("""
    ### æ³¨æ„ç‚¹
    ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ãŒå¿…è¦ã§ã™:
    - ç‰¹å®šã®ã‚¹ã‚­ãƒ«ã«ä¾å­˜ã—ã¦ã„ã‚‹å¯èƒ½æ€§
    - ãƒ¡ãƒ³ãƒãƒ¼é–“ã®çµŒé¨“å¹´æ•°ã®ãƒãƒ©ãƒ³ã‚¹
    - ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«ã®é•ã„
    """)


# 4. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
def main():
    try:
        st.set_page_config(layout="wide", page_title="AIå¾Œç¶™è€…ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ Pro")

        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        df, skills, position_reqs = prepare_data()
        planner = SuccessionPlanner(df, skills, position_reqs)

        # ã‚¿ã‚¤ãƒˆãƒ«
        st.title('ğŸ¢ AIå¾Œç¶™è€…ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ Pro')
        st.markdown("""
        **æ–°ã—ã„ã‚¹ã‚­ãƒ«ä½“ç³»ã«åŸºã¥ãæ¬¡ä¸–ä»£å‹å¾Œç¶™è€…è¨ˆç”»ã‚·ã‚¹ãƒ†ãƒ **  
        å¿ƒèº«å¥å…¨æ€§ã€äººæ ¼ã¨å¿—ã€ä¾¡å€¤è¦³ãƒ»ä¿¡å¿µãªã©6ã¤ã®è¦³ç‚¹ã‹ã‚‰é©æ€§ã‚’è©•ä¾¡
        """)

        # ãƒ¡ã‚¤ãƒ³ç”»é¢
        tab1, tab2 = st.tabs(["ğŸ§‘ å€‹äººåˆ†æ", "ğŸ‘¥ ãƒãƒ¼ãƒ æœ€é©åŒ–"])

        with tab1:
            st.subheader("ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¥å€™è£œè€…æ¨è–¦")

            col1, col2 = st.columns([1, 2])
            with col1:
                position_level = st.radio(
                    "ãƒã‚¸ã‚·ãƒ§ãƒ³éšå±¤",
                    ["ç¬¬1éšå±¤", "ç¬¬2éšå±¤", "ç¬¬3éšå±¤"],
                    horizontal=True,
                    key='pos_level'
                )

                positions = [p for p, req in position_reqs.items()
                             if req["éšå±¤"] == (1 if position_level == "ç¬¬1éšå±¤" else 2 if position_level == "ç¬¬2éšå±¤" else 3)]

                selected_position = st.selectbox("ãƒã‚¸ã‚·ãƒ§ãƒ³é¸æŠ", positions, key='pos_select')

                if st.button("å€™è£œè€…ã‚’åˆ†æ", type="primary", key='analyze_btn'):
                    with st.spinner('å€™è£œè€…ã‚’åˆ†æä¸­...'):
                        st.session_state.recommendations = planner.recommend_candidates(selected_position)
                        st.session_state.selected_position = selected_position

            # è¡¨ç¤ºéƒ¨åˆ†ã®ä¿®æ­£
            with col2:
                if 'recommendations' in st.session_state:
                    st.subheader(f"â­ {st.session_state.selected_position} å€™è£œè€…ãƒˆãƒƒãƒ—3")

                    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
                    # st.write("ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰:")
                    st.write(st.session_state.recommendations)

                    if not st.session_state.recommendations.empty:
                        # fig = px.histogram(st.session_state.recommendations, x='ç·åˆã‚¹ã‚³ã‚¢',
                        # # fig = px.histogram(st.session_state.recommendations, x='count',
                        #                    title='ç·åˆã‚¹ã‚³ã‚¢åˆ†å¸ƒ', nbins=20)
                        # st.plotly_chart(fig, use_container_width=True)

                        fig = px.bar(
                            st.session_state.recommendations.sort_values('ç·åˆã‚¹ã‚³ã‚¢', ascending=False),
                            x='æ°å',
                            y='ç·åˆã‚¹ã‚³ã‚¢',
                            color='ç·åˆã‚¹ã‚³ã‚¢',
                            color_continuous_scale='Bluered',
                            title='å€™è£œè€…åˆ¥ç·åˆã‚¹ã‚³ã‚¢',
                            labels={'ç·åˆã‚¹ã‚³ã‚¢': 'ç·åˆé©æ€§ã‚¹ã‚³ã‚¢', 'æ°å': 'å€™è£œè€…'},
                            hover_data=['éƒ¨ç½²', 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹', 'æ½œåœ¨ã‚¹ã‚³ã‚¢', 'ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢']
                        )
                        # ã‚°ãƒ©ãƒ•ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
                        fig.update_layout(
                            xaxis_tickangle=-45,
                            xaxis_title=None,
                            yaxis_range=[0, 1],
                            height=500,
                            hovermode='x unified',
                            coloraxis_showscale=False,
                            margin=dict(b=150))

                        fig.update_traces(
                            texttemplate='%{y:.2f}',
                            textposition='outside',
                            hovertemplate="<b>%{x}</b><br>ã‚¹ã‚³ã‚¢: %{y:.2f}<br>éƒ¨ç½²: %{customdata[0]}<br>"
                                          "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: %{customdata[1]:.1f}<br>æ½œåœ¨ã‚¹ã‚³ã‚¢: %{customdata[2]:.2f}<br>"
                                          "ã‚¹ã‚­ãƒ«ã‚¹ã‚³ã‚¢: %{customdata[3]:.2f}"
                        )
                        st.plotly_chart(fig, use_container_width=True)


                        # ä¿®æ­£å‰ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ã€ä»¥ä¸‹ã®ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã«å¤‰æ›´
                        # fig = px.bar(
                        #     st.session_state.recommendations.sort_values('ç·åˆã‚¹ã‚³ã‚¢', ascending=False),
                        #     x='æ°å',
                        #     y='ç·åˆã‚¹ã‚³ã‚¢',
                        #     color='ç·åˆã‚¹ã‚³ã‚¢',
                        #     color_continuous_scale='Bluered',
                        #     title='å€™è£œè€…åˆ¥ç·åˆã‚¹ã‚³ã‚¢',
                        #     labels={'ç·åˆã‚¹ã‚³ã‚¢': 'ç·åˆé©æ€§ã‚¹ã‚³ã‚¢', 'æ°å': 'å€™è£œè€…'},
                        #     hover_data=['éƒ¨ç½²', 'çµŒé¨“å¹´æ•°', 'ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹']
                        # )
                        # # ã‚°ãƒ©ãƒ•ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
                        # fig.update_layout(
                        #     xaxis_tickangle=-45,
                        #     xaxis_title=None,
                        #     yaxis_range=[0, 1],
                        #     height=500,
                        #     hovermode='x unified',
                        #     coloraxis_showscale=False,
                        #     margin=dict(b=150)  # ä¸‹éƒ¨ãƒãƒ¼ã‚¸ãƒ³æ‹¡å¤§
                        # )
                        # # ãƒãƒ¼ã®ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
                        # fig.update_traces(
                        #     texttemplate='%{y:.2f}',
                        #     textposition='outside'
                        # )
                        # # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—æ”¹å–„
                        # fig.update_traces(
                        #     hovertemplate="<b>%{x}</b><br>"
                        #                   "ã‚¹ã‚³ã‚¢: %{y:.2f}<br>"
                        #                   "éƒ¨ç½²: %{customdata[0]}<br>"
                        #                   "çµŒé¨“å¹´æ•°: %{customdata[1]}å¹´<br>"
                        #                   "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: %{customdata[2]:.1f}"
                        # )
                        # st.plotly_chart(fig, use_container_width=True)

                        for idx, row in st.session_state.recommendations.iterrows():
                            with st.expander(
                                    f"{idx + 1}ä½: {row['æ°å']} ({row['éƒ¨ç½²']}) ã‚¹ã‚³ã‚¢: {row['ç·åˆã‚¹ã‚³ã‚¢']:.2f}",
                                    expanded=(idx == 0)):
                                col_a, col_b = st.columns([1, 2])
                                with col_a:
                                    # ã‚¹ã‚­ãƒ«ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
                                    fig = go.Figure()
                                    fig.add_trace(go.Scatterpolar(
                                        r=row[skills].values,
                                        theta=skills,
                                        fill='toself',
                                        name='ç¾åœ¨ã®ã‚¹ã‚­ãƒ«',
                                        line_color='#636efa'
                                    ))

                                    # ãƒã‚¸ã‚·ãƒ§ãƒ³è¦ä»¶
                                    reqs = position_reqs[st.session_state.selected_position]
                                    fig.add_trace(go.Scatterpolar(
                                        r=[reqs["å¿…é ˆã‚¹ã‚­ãƒ«"].get(s, 0) for s in skills],
                                        theta=skills,
                                        name='ãƒã‚¸ã‚·ãƒ§ãƒ³è¦ä»¶',
                                        line=dict(color='#FFA15A', dash='dot')
                                    ))

                                    fig.update_layout(
                                        polar=dict(radialaxis=dict(range=[0, 5], visible=True)),
                                        title='ã‚¹ã‚­ãƒ«æ¯”è¼ƒ',
                                        width=400,
                                        height=400
                                    )
                                    st.plotly_chart(fig, use_container_width=True)

                                # with col_b:
                                #     st.markdown(f"""
                                #     ### æ¨è–¦ç†ç”±ã®è©³ç´°
                                #     {row['æ¨è–¦ç†ç”±']}
                                #
                                #     #### å®šæ€§ãƒ‡ãƒ¼ã‚¿åˆ†æ:
                                #     ```
                                #     ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
                                #     ```
                                #     """)
                                with col_b:
                                    st.markdown(f"""
                                    ### æ¨è–¦ç†ç”±ã®è©³ç´°
                                    {row['æ¨è–¦ç†ç”±']}
                                    #### å®šæ€§ãƒ‡ãƒ¼ã‚¿åˆ†æ:
                                    """)
                                    # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯è¡¨ç¤ºï¼ˆã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†ä»˜ãï¼‰
                                    if 'ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯' in row and pd.notnull(row['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯']):
                                        feedback_text = row['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯'].replace('```', 'ï¾Œï¾Ÿï¾›ï½¯ï¾„')  # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜å·ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                                        st.markdown(f"```\n{feedback_text}\n```")
                                    else:
                                        st.warning("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")

                                    # {row['ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯']}
                                    # è©³ç´°åˆ†æ
                        selected_candidate = st.selectbox(
                            "è©³ç´°åˆ†æã™ã‚‹å€™è£œè€…ã‚’é¸æŠ",
                            st.session_state.recommendations['ID'].tolist(),
                            key='detail_select'
                        )

                        if selected_candidate:
                            st.subheader("ğŸ“ˆ 3å¹´é–“ã®æˆé•·äºˆæ¸¬ã¨è‚²æˆè¨ˆç”»")
                            predictions = planner.predict_growth(selected_candidate, st.session_state.selected_position)

                            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
                            st.plotly_chart(plot_growth(predictions, st.session_state.selected_position)[0],
                                            use_container_width=True)

                            # è‚²æˆè¨ˆç”»
                            st.markdown("### æ¨å¥¨è‚²æˆè¨ˆç”»")
                            for plan in predictions['è‚²æˆè¨ˆç”»']:
                                st.markdown(f"- {plan}")

                            # ã‚¹ã‚­ãƒ«é€²åŒ–äºˆæ¸¬
                            st.plotly_chart(plot_growth(predictions, st.session_state.selected_position)[1],
                                            use_container_width=True)
                    else:
                        st.warning("è©²å½“ã™ã‚‹å€™è£œè€…ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¡ä»¶ã‚’ç·©å’Œã—ã¦ãã ã•ã„ã€‚")

        with tab2:
            st.subheader("çµŒå–¶é™£æœ€é©çµ„ã¿åˆã‚ã›åˆ†æ")
            st.info("ç¤¾é•·å€™è£œã¨ç¬¬2éšå±¤ãƒã‚¸ã‚·ãƒ§ãƒ³ã®æœ€é©ãªçµ„ã¿åˆã‚ã›ã‚’AIãŒææ¡ˆã—ã¾ã™")

            if st.button("æœ€é©ãƒãƒ¼ãƒ ã‚’ç”Ÿæˆ", type="primary", key='team_btn'):
                with st.spinner('AIãŒæœ€é©ãªãƒãƒ¼ãƒ çµ„ã¿åˆã‚ã›ã‚’åˆ†æä¸­...'):
                    st.session_state.top_teams = planner.analyze_optimal_team()

            if 'top_teams' in st.session_state:
                for i, team in enumerate(st.session_state.top_teams, 1):
                    with st.expander(f"ğŸ† æœ€é©ãƒãƒ¼ãƒ æ¡ˆ {i}", expanded=i == 1):
                        display_team_analysis(planner, team, df)
    except Exception as e:
        st.error(f"é‡å¤§ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.write("ã‚¨ãƒ©ãƒ¼è©³ç´°:")
        st.exception(e)


if __name__ == "__main__":
    main()
