import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import MinMaxScaler
import japanize_matplotlib
import random
import functools
from concurrent.futures import ThreadPoolExecutor


# 1. æ•°æ®å‡†å¤‡ï¼ˆæ–°çš„æŠ€èƒ½ä½“ç³»ï¼‰
def prepare_data():
    skills = ['èº«å¿ƒå¥åº·', 'äººæ ¼å’Œå¿—å‘', 'ä»·å€¼è§‚å’Œä¿¡å¿µ', 'ä¸šåŠ¡èƒ½åŠ›', 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›', 'èŒåŠ¡ç»å†å’Œä¸šç»©']

    position_requirements = {
        "æ€»è£": {
            "å¿…éœ€æŠ€èƒ½": {s: 5 for s in skills if s != 'ä¸šåŠ¡èƒ½åŠ›'},
            "æƒé‡": {'èº«å¿ƒå¥åº·': 0.2, 'äººæ ¼å’Œå¿—å‘': 0.25, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.2, 'ä¸šåŠ¡èƒ½åŠ›': 0.1,
                     'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.15, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.1},
            "å±‚çº§": 1,
            "è¯´æ˜": "å…¨å…¬å¸çš„æ„¿æ™¯åˆ¶å®šå’Œç»è¥å†³ç­–æ˜¯ä¸»è¦èŒè´£",
            "å…³é”®è¯": ["ç»è¥", "æ„¿æ™¯", "åˆ¤æ–­åŠ›", "å†³æ–­åŠ›"]
        },
        "ç»è¥ä¼åˆ’æœ¬éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {'èº«å¿ƒå¥åº·': 0.15, 'äººæ ¼å’Œå¿—å‘': 0.2, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.15, 'ä¸šåŠ¡èƒ½åŠ›': 0.15,
                     'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.25, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.1},
            "å±‚çº§": 2,
            "è¯´æ˜": "ä¸­é•¿æœŸç»è¥è®¡åˆ’çš„åˆ¶å®šå’Œæ‰§è¡Œç®¡ç†",
            "å…³é”®è¯": ["è®¡åˆ’", "æƒ…æ™¯", "åˆ†æ", "æˆ˜ç•¥"]
        },
        "äº‹ä¸šéƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {'èº«å¿ƒå¥åº·': 0.15, 'äººæ ¼å’Œå¿—å‘': 0.15, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.15, 'ä¸šåŠ¡èƒ½åŠ›': 0.25,
                     'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.2, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.1},
            "å±‚çº§": 2,
            "è¯´æ˜": "äº‹ä¸šå•ä½çš„P&Lè´£ä»»å’Œæˆ˜ç•¥æ‰§è¡Œ",
            "å…³é”®è¯": ["äº‹ä¸š", "æ”¶ç›Š", "å®¢æˆ·", "å¸‚åœº"]
        },
        "å†…éƒ¨å®¡è®¡éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½":  {s: 3 for s in skills},
            "æƒé‡": {
                'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.3,
                'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.25,
                'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.2,
                'èº«å¿ƒå¥åº·': 0.1,
                'äººæ ¼å’Œå¿—å‘': 0.1,
                'ä¸šåŠ¡èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "ä¼ä¸šæ²»ç†å’Œåˆè§„æ€§çš„å½»åº•å®¡è®¡å’Œç®¡ç†",
            "å…³é”®è¯": ["å®¡è®¡", "åˆè§„æ€§", "é£é™©ç®¡ç†", "æ²»ç†"]
        },
        "Aäº‹ä¸šéƒ¨ãƒ»ä¸œäº¬åˆ†å…¬å¸æ€»ç»ç†": {
            "å¿…éœ€æŠ€èƒ½": {s: 3 for s in skills},
            "æƒé‡": {
                'ä¸šåŠ¡èƒ½åŠ›': 0.3,
                'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.25,
                'èº«å¿ƒå¥åº·': 0.15,
                'äººæ ¼å’Œå¿—å‘': 0.15,
                'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.1,
                'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "ä¸œäº¬åœ°åŒºçš„äº‹ä¸šæˆ˜ç•¥æ‰§è¡Œå’Œé”€å”®ç›®æ ‡çš„è¾¾æˆç®¡ç†",
            "å…³é”®è¯": ["åœ°åŒºæˆ˜ç•¥", "é”€å”®ç®¡ç†", "å›¢é˜Ÿç»Ÿç‡", "å¸‚åœºå¼€æ‹“"]
        },
        # å…¶ä»–èŒä½å®šä¹‰
        "Aäº‹ä¸šéƒ¨ãƒ»å¤§é˜ªåˆ†å…¬å¸æ€»ç»ç†": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä¸šåŠ¡èƒ½åŠ›': 0.3, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.25, 'èº«å¿ƒå¥åº·': 0.15,
                'äººæ ¼å’Œå¿—å‘': 0.15, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.1, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "å¤§é˜ªåœ°åŒºçš„äº‹ä¸šå±•å¼€å’Œæ”¶ç›Šç›®æ ‡çš„è¾¾æˆç®¡ç†",
            "å…³é”®è¯": ["åœ°åŒºç®¡ç†", "æ”¶ç›Šç®¡ç†", "æ®ç‚¹è¿è¥"]
        },
        "Aäº‹ä¸šéƒ¨ãƒ»æ€»éƒ¨ãƒ»é”€å”®ç»Ÿæ‹¬éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills if s != 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›'},
            "æƒé‡": {
                'ä¸šåŠ¡èƒ½åŠ›': 0.35, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.3, 'èº«å¿ƒå¥åº·': 0.15,
                'äººæ ¼å’Œå¿—å‘': 0.1, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.05, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "å…¨äº‹ä¸šéƒ¨çš„é”€å”®æˆ˜ç•¥åˆ¶å®šå’Œé”€å”®å›¢é˜Ÿçš„ç»Ÿæ‹¬ç®¡ç†",
            "å…³é”®è¯": ["é”€å”®æˆ˜ç•¥", "é”€å”®ç®¡ç†", "å›¢é˜ŸåŸ¹å…»"]
        },
        "Aäº‹ä¸šéƒ¨ãƒ»æ€»éƒ¨ãƒ»æŠ€æœ¯ç»Ÿæ‹¬éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä¸šåŠ¡èƒ½åŠ›': 0.4, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.25, 'èº«å¿ƒå¥åº·': 0.1,
                'äººæ ¼å’Œå¿—å‘': 0.1, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.1, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "æŠ€æœ¯å¼€å‘æˆ˜ç•¥çš„åˆ¶å®šå’ŒæŠ€æœ¯éƒ¨é—¨çš„ç»¼åˆç®¡ç†",
            "å…³é”®è¯": ["æŠ€æœ¯å¼€å‘", "åˆ›æ–°", "ç ”ç©¶ç®¡ç†"]
        },
        "Aäº‹ä¸šéƒ¨ãƒ»æ€»éƒ¨ãƒ»æµ·å¤–ç»Ÿæ‹¬éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.3, 'ä¸šåŠ¡èƒ½åŠ›': 0.25, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.2,
                'èº«å¿ƒå¥åº·': 0.1, 'äººæ ¼å’Œå¿—å‘': 0.1, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "æµ·å¤–äº‹ä¸šçš„å±•å¼€æˆ˜ç•¥åˆ¶å®šå’Œå…¨çƒäº‹ä¸šçš„ç»Ÿæ‹¬",
            "å…³é”®è¯": ["å…¨çƒæˆ˜ç•¥", "è·¨æ–‡åŒ–åº”å¯¹", "æµ·å¤–å±•å¼€"]
        },
        "Bäº‹ä¸šéƒ¨ãƒ»é”€å”®ç»Ÿæ‹¬éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä¸šåŠ¡èƒ½åŠ›': 0.35, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.3, 'èº«å¿ƒå¥åº·': 0.15,
                'äººæ ¼å’Œå¿—å‘': 0.1, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.05, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "Bäº‹ä¸šéƒ¨æ•´ä½“çš„é”€å”®æˆ˜ç•¥åˆ¶å®šå’Œé”€å”®ç›®æ ‡çš„è¾¾æˆç®¡ç†",
            "å…³é”®è¯": ["é”€å”®æˆ˜ç•¥", "å®¢æˆ·ç®¡ç†", "é”€å”®ä¿ƒè¿›"]
        },
        "Bäº‹ä¸šéƒ¨ãƒ»æŠ€æœ¯ç»Ÿæ‹¬éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä¸šåŠ¡èƒ½åŠ›': 0.4, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.25, 'èº«å¿ƒå¥åº·': 0.1,
                'äººæ ¼å’Œå¿—å‘': 0.1, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.1, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "Bäº‹ä¸šéƒ¨çš„æŠ€æœ¯å¼€å‘æˆ˜ç•¥å’ŒæŠ€æœ¯å›¢é˜Ÿçš„ç»¼åˆç®¡ç†",
            "å…³é”®è¯": ["æŠ€æœ¯ç®¡ç†", "å¼€å‘æˆ˜ç•¥", "è´¨é‡ç®¡ç†"]
        },
        "Bäº‹ä¸šéƒ¨ãƒ»å¼€å‘ç»Ÿæ‹¬éƒ¨é•¿": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä¸šåŠ¡èƒ½åŠ›': 0.45, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.25, 'èº«å¿ƒå¥åº·': 0.1,
                'äººæ ¼å’Œå¿—å‘': 0.1, 'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.05, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "æ–°äº§å“å¼€å‘æˆ˜ç•¥çš„åˆ¶å®šå’Œå¼€å‘è¿‡ç¨‹çš„ä¼˜åŒ–",
            "å…³é”®è¯": ["äº§å“å¼€å‘", "é¡¹ç›®ç®¡ç†", "åˆ›æ–°"]
        },
        "æµ·å¤–å­å…¬å¸æ€»ç»ç†": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.3, 'ä¸šåŠ¡èƒ½åŠ›': 0.25, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.2,
                'èº«å¿ƒå¥åº·': 0.15, 'äººæ ¼å’Œå¿—å‘': 0.1, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "æµ·å¤–å­å…¬å¸çš„ç»è¥ç®¡ç†å’Œå½“åœ°æˆ˜ç•¥çš„æ‰§è¡Œç»Ÿç­¹",
            "å…³é”®è¯": ["å…¨çƒç»è¥", "æœ¬åœ°é€‚åº”", "æµ·å¤–æ®ç‚¹ç®¡ç†"]
        },
        "å­¦ä¹ åŠ›è€…": {
            "å¿…éœ€æŠ€èƒ½": {s: 4 for s in skills},
            "æƒé‡": {
                'ä»·å€¼è§‚å’Œä¿¡å¿µ': 0.3, 'ä¸šåŠ¡èƒ½åŠ›': 0.25, 'èŒåŠ¡ç»å†å’Œä¸šç»©': 0.2,
                'èº«å¿ƒå¥åº·': 0.15, 'äººæ ¼å’Œå¿—å‘': 0.1, 'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': 0.05
            },
            "å±‚çº§": 3,
            "è¯´æ˜": "å­¦ä¹ æ–°æŠ€æœ¯å’Œæ„¿æ™¯ï¼Œå¹¶å°†å…¶åº”ç”¨äºç»è¥æˆ˜ç•¥",
            "å…³é”®è¯": ["å­¦ä¹ ", "æ–°æŠ€æœ¯", "æ„¿æ™¯"]
        }
    }

    # å¼·åŒ–ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆæ–°ã—ã„ã‚¹ã‚­ãƒ«ä½“ç³»ã«åˆã‚ã›ã¦æ›´æ–°ï¼‰
    # å¼ºåŒ–çš„åé¦ˆåº“ï¼ˆæ ¹æ®æ–°çš„æŠ€èƒ½ä½“ç³»æ›´æ–°ï¼‰
    feedback_library = {
        'èº«å¿ƒå¥åº·': [
            "å…¨å¹´æ²¡æœ‰è¯·ç—…å‡ï¼Œä¿æŒäº†é«˜æ°´å¹³çš„è¡¨ç°",
            "åœ¨å‹åŠ›ç¯å¢ƒä¸‹å§‹ç»ˆä¿æŒå†·é™ï¼Œç¨³å®šäº†å›¢é˜Ÿ",
            "ä¸¥æ ¼ç®¡ç†å¥åº·ï¼Œåœ¨å…¬å¸é©¬æ‹‰æ¾æ¯”èµ›ä¸­è·èƒœï¼Œä½“åŠ›å‡ºä¼—",
            "å®è·µå·¥ä½œä¸ç”Ÿæ´»çš„å¹³è¡¡ï¼Œå±•ç¤ºäº†é«˜ç”Ÿäº§åŠ›çš„å·¥ä½œæ–¹å¼"
        ],
        'äººæ ¼å’Œå¿—å‘': [
            "æ— ç§å¥‰çŒ®äºå…¬å¸çš„å‘å±•ï¼Œå—åˆ°å…¨ä½“å‘˜å·¥çš„å°Šæ•¬",
            "æ‹¥æœ‰å¼ºçƒˆçš„ç¤¾ä¼šè´¡çŒ®å¿—å‘ï¼Œç§¯ææ¨åŠ¨CSRæ´»åŠ¨",
            "å§‹ç»ˆä»¥å…¬å¹³çš„ç«‹åœºåˆ¤æ–­äº‹ç‰©ï¼Œå—åˆ°æ‰€æœ‰äººçš„ä¿¡èµ–",
            "æ˜ç¡®æè¿°æœªæ¥åå¹´çš„æ„¿æ™¯ï¼Œæ¿€åŠ±å‘¨å›´çš„äºº"
        ],
        'ä»·å€¼è§‚å’Œä¿¡å¿µ': [
            "åšæŒâ€˜å®¢æˆ·ç¬¬ä¸€â€™çš„ä¿¡å¿µï¼Œåœ¨å›°éš¾å±€é¢ä¸­ä¿æŒä¼¦ç†è§‚",
            "ä½“ç°å…¬å¸çš„æ ¸å¿ƒä»·å€¼è§‚ï¼Œæˆä¸ºæ–°å‘˜å·¥çš„æ¦œæ ·",
            "åœ¨ä¸ç¡®å®šçš„æƒ…å†µä¸‹ä¹Ÿæœ‰æ˜ç¡®çš„åˆ¤æ–­æ ‡å‡†ï¼Œè¡Œä¸ºä¸€è‡´",
            "å®è·µå¤šæ ·æ€§å’ŒåŒ…å®¹æ€§ï¼Œå……åˆ†åˆ©ç”¨å¤šæ ·åŒ–çš„äººæ‰"
        ],
        'ä¸šåŠ¡èƒ½åŠ›': [
            "åœ¨è´Ÿè´£çš„å·¥ä½œä¸­å§‹ç»ˆå–å¾—é«˜æˆæœï¼Œå¯¹éƒ¨é—¨ç›®æ ‡çš„è¾¾æˆåšå‡ºé‡å¤§è´¡çŒ®",
            "æ”¹å–„å¤æ‚çš„ä¸šåŠ¡æµç¨‹ï¼Œä½¿éƒ¨é—¨æ•´ä½“æ•ˆç‡æé«˜äº†30%",
            "æ‹¥æœ‰æ·±åšçš„ä¸“ä¸šçŸ¥è¯†ï¼Œå¤šæ¬¡æˆåŠŸè§£å†³å›°éš¾é—®é¢˜",
            "è¿…é€Ÿé€‚åº”æ–°å·¥ä½œï¼ŒçŸ­æ—¶é—´å†…æˆä¸ºé«˜ç”Ÿäº§åŠ›çš„æˆå‘˜"
        ],
        'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': [
            "æ·±å…¥ç†è§£è´¢åŠ¡æŠ¥è¡¨ï¼Œæå‡ºé€‚å½“çš„èµ„æºåˆ†é…å»ºè®®ï¼Œæ”¹å–„æ”¶ç›Š",
            "å‚ä¸é«˜å±‚ç®¡ç†å†³ç­–ï¼Œæä¾›å»ºè®¾æ€§æ„è§",
            "è´Ÿè´£è¯„ä¼°å¹¶è´­é¡¹ç›®ï¼Œè¿›è¡Œé€‚å½“çš„ä¼ä¸šä»·å€¼è¯„ä¼°",
            "æ“…é•¿åˆ¶å®šå°†ç»è¥æˆ˜ç•¥ä»˜è¯¸å®æ–½çš„å…·ä½“è¡ŒåŠ¨è®¡åˆ’"
        ],
        'èŒåŠ¡ç»å†å’Œä¸šç»©': [
            "åœ¨è¿‡å»äº”å¹´ä¸­ç»å†äº†ä¸‰ä¸ªä¸åŒéƒ¨é—¨ï¼Œå¹¶åœ¨æ¯ä¸ªéƒ¨é—¨éƒ½å–å¾—äº†æˆç»©",
            "æˆåŠŸå¯åŠ¨æ–°ä¸šåŠ¡ï¼Œä¸‰å¹´å†…å®ç°äº†10äº¿æ—¥å…ƒçš„é”€å”®é¢",
            "æœ‰æµ·å¤–æ´¾é£ç»éªŒï¼Œé¢†å¯¼å›½é™…é¡¹ç›®çš„ä¸šç»©",
            "æ‹…ä»»è¡Œä¸šåä¼šçš„å§”å‘˜ï¼Œåœ¨ç¤¾å¤–æœ‰å¹¿æ³›çš„ç½‘ç»œ"
        ],
        'æ½œåœ¨èƒ½åŠ›': [
            "è™½ç„¶åªå‘æŒ¥äº†ä¸€éƒ¨åˆ†ï¼Œä½†å¦‚æœæœ‰é€‚å½“çš„æŒ‡å¯¼ï¼Œå¯èƒ½ä¼šæœ‰é£è·ƒæ€§çš„æˆé•¿",
            "è¿…é€Ÿé€‚åº”æ–°å·¥ä½œï¼ŒçŸ­æ—¶é—´å†…æˆä¸ºé«˜ç”Ÿäº§åŠ›çš„æˆå‘˜",
            "åœ¨é¢å¯¹å›°éš¾é—®é¢˜æ—¶è¡¨ç°å‡ºçš„éŸ§æ€§éåŒå¯»å¸¸",
            "è‡ªå­¦èƒ½åŠ›å¼ºï¼Œç§¯æåœ¨å·¥ä½œä¹‹å¤–å–å¾—ç›¸å…³èµ„æ ¼"
        ],
        'ä¸šç»©': [
            "åœ¨XXé¡¹ç›®ä¸­ï¼Œåœ¨é¢„ç®—å‡å°‘15%çš„æƒ…å†µä¸‹æå‰å®Œæˆäº†è®¡åˆ’",
            "åœ¨æ–°å®¢æˆ·å¼€å‘ä¸­ï¼Œé€šè¿‡ç‹¬ç‰¹çš„æ–¹æ³•ä½¿å¹´é”€å”®é¢å¢åŠ äº†25%",
            "å¼•å…¥æé«˜å›¢é˜Ÿç”Ÿäº§åŠ›çš„æªæ–½ï¼Œä½¿é¡¹ç›®æ‰§è¡Œæ—¶é—´å¹³å‡ç¼©çŸ­äº†30%"
        ],
        'æˆé•¿': [
            "å…¥èŒä¸‰å¹´ï¼Œå·²ç»æ‹…ä»»äº†äº”ååè¾ˆå‘˜å·¥çš„å¯¼å¸ˆ",
            "é›†ä¸­æ”¹å–„äº†ä¸æ“…é•¿çš„æ¼”è®²æŠ€å·§ï¼Œç°åœ¨åœ¨å…¬å¸æ¯”èµ›ä¸­è·èƒœ",
            "è‹±è¯­èƒ½åŠ›æœ‰é—®é¢˜ï¼Œä½†é€šè¿‡è‡ªå­¦å°†TOEICåˆ†æ•°æé«˜äº†300åˆ†ï¼Œå‚ä¸äº†å›½é™…é¡¹ç›®"
        ]
    }
    # ç”Ÿæˆ150åå‘˜å·¥æ•°æ®
    np.random.seed(42)
    data = []
    departments = ['é”€å”®', 'å¼€å‘', 'ç”Ÿäº§', 'äººäº‹', 'ç»è¥ä¼åˆ’']

    for i in range(150):
        dept = np.random.choice(departments)
        emp = {
            'ID': f'E{i + 1:03d}',
            'å§“å': f'å‘˜å·¥{i + 1}',
            'å¹´é¾„': np.random.randint(30, 56),
            'éƒ¨é—¨': dept,
            'ç»éªŒå¹´æ•°': np.random.randint(3, 26),
            'è¡¨ç°': np.clip(np.random.normal(3.8, 0.8), 1, 5),
            'æ½œåœ¨åŠ›': np.clip(np.random.normal(0.7, 0.15), 0.3, 1.0),
            'æˆé•¿æ„æ„¿': np.clip(np.random.normal(0.8, 0.1), 0.5, 1.0),
            'æ€§æ ¼ç‰¹æ€§': random.choice(['æ…é‡', 'ç§¯æ', 'åè°ƒæ€§', 'åˆ†ææ€§', 'åˆ›é€ æ€§', 'çƒ­æƒ…', 'å†·é™', 'æŒ‘æˆ˜æ€§'])
        }

        # åŸºäºæ–°çš„æŠ€èƒ½ä½“ç³»è¿›è¡Œè¯„ä»·
        for skill in skills:
            base = np.random.normal(3.8, 0.8) * (0.7 + emp['æ½œåœ¨åŠ›'] * 0.5)
            if dept == 'ç»è¥ä¼åˆ’' and skill in ['ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›', 'ä»·å€¼è§‚å’Œä¿¡å¿µ']:
                base += 1.5
            elif dept == 'é”€å”®' and skill in ['ä¸šåŠ¡èƒ½åŠ›', 'èŒåŠ¡ç»å†å’Œä¸šç»©']:
                base += 1.0
            elif dept == 'å¼€å‘' and skill in ['ä¸šåŠ¡èƒ½åŠ›', 'èº«å¿ƒå¥åº·']:
                base += 0.7
            emp[skill] = np.clip(base, 1, 5)

        # ç”Ÿæˆåé¦ˆï¼ˆæ ¹æ®æ–°çš„æŠ€èƒ½ä½“ç³»æ›´æ–°ï¼‰
        feedback_parts = []

        # 1. åŸºäºæŠ€èƒ½çš„è¯„è®ºï¼ˆä»å¼ºé¡¹æŠ€èƒ½ä¸­é€‰æ‹©2æ¡ï¼‰
        strong_skills = [s for s in skills if emp[s] >= 4]
        if len(strong_skills) >= 2:
            selected_skills = np.random.choice(strong_skills, 2, replace=False)
            for skill in selected_skills:
                feedback_parts.append(random.choice(feedback_library[skill]))

        # 2. æ½œåœ¨èƒ½åŠ›è¯„è®ºï¼ˆ60%çš„æ¦‚ç‡æ·»åŠ ï¼‰
        if random.random() < 0.6:
            feedback_parts.append(random.choice(feedback_library['æ½œåœ¨èƒ½åŠ›']))

        # 3. æ€§æ ¼ç‰¹æ€§è¯„è®º
        feedback_parts.append(f"æ€§æ ¼ç‰¹æ€§: {emp['æ€§æ ¼ç‰¹æ€§']}ï¼Œ{random.choice(feedback_library['äººæ ¼å’Œå¿—å‘'])}")

        # 4. ä¸šç»©æˆ–æˆé•¿æ•…äº‹ï¼ˆæ·»åŠ å…¶ä¸­ä¸€æ¡ï¼‰
        feedback_parts.append(random.choice([
            "ã€ä¸šç»©ã€‘" + random.choice(feedback_library['ä¸šç»©']),
            "ã€æˆé•¿ã€‘" + random.choice(feedback_library['æˆé•¿'])
        ]))

        # éšæœºæ‰“ä¹±åé¦ˆé¡ºåº
        random.shuffle(feedback_parts)
        emp['åé¦ˆ'] = "â–  " + "\nâ–  ".join(feedback_parts)
        data.append(emp)

        # éªŒè¯æŠ€èƒ½ç”Ÿæˆé€»è¾‘
        print("ç”Ÿæˆçš„æŠ€èƒ½å€¼ç»Ÿè®¡:")
        for skill in skills:
            values = [emp[skill] for emp in data]
            # print(f"{skill}: å¹³å‡={np.mean(values):.2f} æœ€å¤§={np.max(values):.2f} æœ€å°={np.min(values):.2f}")

    # å°†æ•°æ®å†™å…¥åˆ°excelæ–‡ä»¶ä¸­
    df = pd.DataFrame(data)
    df.to_excel('data.xlsx', index=False)

    return pd.DataFrame(data), skills, position_requirements


# 2. æ¨èå¼•æ“ï¼ˆæ”¯æŒæ–°çš„æŠ€èƒ½ä½“ç³»ï¼‰
class SuccessionPlanner:
    def __init__(self, df, skills, position_reqs):
        self.df = df
        self.skills = skills
        self.position_reqs = position_reqs

        # åˆå§‹åŒ–ç¼©æ”¾å™¨
        self.scalers = {
            'skill': MinMaxScaler().fit(df[skills]),
            'performance': MinMaxScaler().fit(df[['è¡¨ç°']])
        }

        # æ–‡æœ¬åˆ†æè®¾ç½®
        self.vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),
            max_features=500,
            stop_words=['ãŒ', 'ã‚’', 'ã«', 'ã®', 'ã¯', 'ã§', 'ãŸ'],
            token_pattern=r'(?u)\b\w+\b'
        )
        self.tfidf_matrix = self.vectorizer.fit_transform(df['åé¦ˆ'])

        # æŠ€èƒ½å…³é”®è¯æ˜ å°„
        self.skill_keywords = {
            'èº«å¿ƒå¥åº·': ['å¥åº·', 'ä½“åŠ›', 'å‹åŠ›', 'è€åŠ›', 'æŒä¹…åŠ›', 'å¿ƒç†'],
            'äººæ ¼å’Œå¿—å‘': ['äººæ ¼', 'å¿—å‘', 'ä¿¡å¿µ', 'ä¼¦ç†', 'ç†å¿µ', 'é¢†å¯¼åŠ›'],
            'ä»·å€¼è§‚å’Œä¿¡å¿µ': ['ä»·å€¼è§‚', 'ä¿¡å¿µ', 'ä¼¦ç†', 'åˆ¤æ–­', 'æ ‡å‡†', 'å“²å­¦'],
            'ä¸šåŠ¡èƒ½åŠ›': ['ä¸šåŠ¡', 'æ•ˆç‡', 'ç”Ÿäº§åŠ›', 'ä¸“ä¸š', 'æ‰§è¡Œ', 'æŠ€èƒ½'],
            'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': ['ç»è¥', 'è´¢åŠ¡', 'æˆ˜ç•¥', 'å†³ç­–', 'å¹¶è´­', 'æ²»ç†'],
            'èŒåŠ¡ç»å†å’Œä¸šç»©': ['ä¸šç»©', 'ç»éªŒ', 'é¡¹ç›®', 'æˆæœ', 'èŒä¸š', 'å®åŠ¡']
        }

        # åŸ¹å…»è®¡åˆ’
        self.development_plans = {
            'èº«å¿ƒå¥åº·': [
                "å¥åº·ç®¡ç†è®¡åˆ’ï¼ˆ6ä¸ªæœˆï¼‰",
                "å‹åŠ›ç®¡ç†åŸ¹è®­",
                "å¿ƒç†å¥åº·è®­ç»ƒ"
            ],
            'äººæ ¼å’Œå¿—å‘': [
                "é¢†å¯¼åŠ›å“²å­¦åŸ¹è®­",
                "é«˜ç®¡æŒ‡å¯¼è®¡åˆ’",
                "ç¤¾ä¼šè´¡çŒ®é¡¹ç›®é¢†å¯¼ç»éªŒ"
            ],
            'ä»·å€¼è§‚å’Œä¿¡å¿µ': [
                "ä¼ä¸šç†å¿µæ·±åŒ–ç ”è®¨ä¼š",
                "é«˜ç®¡ä¼¦ç†åŸ¹è®­",
                "å¤šæ ·æ€§åŸ¹è®­"
            ],
            'ä¸šåŠ¡èƒ½åŠ›': [
                "ä¸“ä¸šé¢†åŸŸé«˜çº§åŸ¹è®­",
                "ä¸šåŠ¡æµç¨‹æ”¹è¿›é¡¹ç›®",
                "è·¨éƒ¨é—¨è½®å²—"
            ],
            'ç»è¥å®åŠ¡çš„çŸ¥è¯†å’Œå‘æŒ¥èƒ½åŠ›': [
                "ç»è¥æ¨¡æ‹Ÿè®¡åˆ’",
                "è´¢åŠ¡åˆ†æä¸“å®¶åŸ¹è®­è¯¾ç¨‹",
                "è‘£äº‹ä¼šè§‚å¯Ÿå‘˜ç»éªŒ"
            ],
            'èŒåŠ¡ç»å†å’Œä¸šç»©': [
                "å†…éƒ¨å…¬å¼€æ‹›è˜é¡¹ç›®å‚ä¸",
                "æµ·å¤–æ´¾é£è®¡åˆ’",
                "æ–°ä¸šåŠ¡å¯åŠ¨ä»»åŠ¡å°ç»„"
            ]
        }

    @functools.lru_cache(maxsize=32)
    def get_text_similarity(self, position):
        """æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        reqs = self.position_reqs[position]
        pos_keywords = " ".join(reqs.get("å…³é”®è¯", []))
        pos_vector = self.vectorizer.transform([pos_keywords])
        return cosine_similarity(self.tfidf_matrix, pos_vector)

    def extract_potential(self, feedback):
        """å¼ºåŒ–çš„æ½œåœ¨èƒ½åŠ›æå–é€»è¾‘"""
        signals = [
            ('å¯èƒ½æ€§', 0.3), ('æ½œåŠ›', 0.3), ('æˆé•¿', 0.2),
            ('æå‡ç©ºé—´', 0.4), ('é€‚åº”åŠ›', 0.2), ('æœŸæœ›', 0.3),
            ('é£è·ƒ', 0.4), ('ç´ è´¨', 0.3), ('å‰æ™¯', 0.3)
        ]

        score = 0
        for keyword, weight in signals:
            if keyword in feedback:
                score += weight

        # å…·ä½“äº‹ä¾‹çš„æœ‰æ— 
        if any(word in feedback for word in ['ä¸šç»©', 'æˆæœ', 'è¾¾æˆ', 'æˆåŠŸ']):
            score += 0.2

        # æˆé•¿æ•…äº‹
        if any(word in feedback for word in ['æ”¹è¿›', 'æå‡', 'æŒæ¡', 'æˆé•¿']):
            score += 0.2

        return min(1.0, score)

    def recommend_candidates(self, position, top_n=3):
        try:
            reqs = self.position_reqs[position]
            print(f"\n=== å¼€å§‹æ¨è {position} ===")

            # å¤åˆ¶æ‰€æœ‰å€™é€‰äºº
            candidates_df = self.df.copy()

            # è®¡ç®—æŠ€èƒ½ä¸è¶³åº¦ï¼ˆä¸å¿…éœ€æŠ€èƒ½çš„å·®è·ï¼‰
            skill_shortfalls = []
            for skill, min_level in reqs["å¿…éœ€æŠ€èƒ½"].items():
                candidates_df[f'{skill}_ä¸è¶³'] = np.clip(min_level - 0.5 - candidates_df[skill], 0, None)
                skill_shortfalls.append(f'{skill}_ä¸è¶³')

            # è®¡ç®—æŠ€èƒ½è¯„åˆ†
            skill_weights = np.array([reqs["æƒé‡"].get(s, 0) for s in self.skills])
            candidates_df['æŠ€èƒ½è¯„åˆ†'] = candidates_df[self.skills].values.dot(skill_weights)

            # ç¼©æ”¾
            candidates_df['æŠ€èƒ½è¯„åˆ†_ç¼©æ”¾'] = self.scalers['skill'].transform(candidates_df[self.skills]).mean(axis=1)
            candidates_df['è¡¨ç°_ç¼©æ”¾'] = self.scalers['performance'].transform(candidates_df[['è¡¨ç°']]).flatten()

            # æ–‡æœ¬åŒ¹é…è¯„åˆ†
            text_sim = self.get_text_similarity(position)
            candidates_df['æ–‡æœ¬è¯„åˆ†'] = text_sim[candidates_df.index].flatten()

            # æ½œåœ¨èƒ½åŠ›è¯„åˆ†
            candidates_df['æ½œåœ¨è¯„åˆ†'] = candidates_df['åé¦ˆ'].apply(self.extract_potential)

            # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆåº”ç”¨æŠ€èƒ½ä¸è¶³çš„æƒ©ç½šï¼‰
            skill_penalty = candidates_df[skill_shortfalls].sum(axis=1) * 0.1  # æ¯ä¸è¶³1ç‚¹æ‰£10%
            candidates_df['ç»¼åˆè¯„åˆ†'] = (
                0.4 * candidates_df['æŠ€èƒ½è¯„åˆ†_ç¼©æ”¾'] +
                0.3 * candidates_df['è¡¨ç°_ç¼©æ”¾'] +
                0.2 * candidates_df['æ–‡æœ¬è¯„åˆ†'] +
                0.1 * candidates_df['æ½œåœ¨è¯„åˆ†']
            ) * (1 - skill_penalty)  # åº”ç”¨æƒ©ç½š

            # ç”Ÿæˆæ¨èç†ç”±
            candidates_df['æ¨èç†ç”±'] = candidates_df.apply(
                lambda x: self.generate_reason(x, position), axis=1)

            result_cols = ['ID', 'å§“å', 'éƒ¨é—¨'] + self.skills + ['è¡¨ç°', 'æŠ€èƒ½è¯„åˆ†', 'æ–‡æœ¬è¯„åˆ†', 'æ½œåœ¨è¯„åˆ†', 'ç»¼åˆè¯„åˆ†', 'æ¨èç†ç”±', 'åé¦ˆ']
            result_df = candidates_df[result_cols].nlargest(top_n, 'ç»¼åˆè¯„åˆ†').reset_index(drop=True)
            return result_df
        except Exception as e:
            print(f"æ¨èè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            return pd.DataFrame()

    def generate_reason(self, candidate, position):
        reqs = self.position_reqs[position]
        reasons = []

        # æŠ€èƒ½é€‚é…æ€§ï¼ˆæ˜ç¡®ä¸è¶³ç‚¹ï¼‰
        missing_skills = []
        for skill, min_level in reqs["å¿…éœ€æŠ€èƒ½"].items():
            actual = candidate[skill]
            required = min_level - 0.5
            if actual >= required:
                level = "â—" if actual >= 4.5 else "â—‹"
                reasons.append(f"{skill}{level}({actual:.1f}/5)")
            else:
                missing_skills.append(f"{skill}(ä¸è¶³:{required - actual:.1f})")

        if missing_skills:
            reasons.append(f"â€»éœ€è¦æ”¹è¿›çš„æŠ€èƒ½: {', '.join(missing_skills)}")

        # åé¦ˆåˆ†æ
        feedback_analysis = []

        # å…³é”®è¯æå–
        matched_keywords = []
        for skill in reqs["å¿…éœ€æŠ€èƒ½"]:
            if any(kw in candidate['åé¦ˆ'] for kw in self.skill_keywords.get(skill, [])):
                matched_keywords.append(skill)
        if matched_keywords:
            feedback_analysis.append(f"æ£€æµ‹åˆ°{len(matched_keywords)}ä¸ªæŠ€èƒ½å…³é”®è¯")

        # å…·ä½“äº‹ä¾‹
        if any(c in candidate['åé¦ˆ'] for c in ['ä¸šç»©', 'æˆæœ', 'è¾¾æˆ']):
            feedback_analysis.append("æœ‰å…·ä½“äº‹ä¾‹")

        # æˆé•¿è®°å½•
        if any(c in candidate['åé¦ˆ'] for c in ['æˆé•¿', 'æ”¹è¿›', 'æå‡']):
            feedback_analysis.append("æœ‰æˆé•¿è®°å½•")

        if feedback_analysis:
            reasons.append("å®šæ€§åˆ†æ: " + ", ".join(feedback_analysis))

        # æ½œåœ¨èƒ½åŠ›
        potential_score = self.extract_potential(candidate['åé¦ˆ'])
        if potential_score > 0.6:
            reasons.append(f"æ½œåœ¨èƒ½åŠ›: {potential_score:.0%}")
            reasons.append(f"æˆé•¿æ„æ„¿: {candidate['æˆé•¿æ„æ„¿']:.1f}/1.0")

        return f"ã€{position}é€‚é…æ€§ã€‘\n" + "\n".join(f"ãƒ»{r}" for r in reasons)

    def predict_growth(self, candidate_id, position):
        candidate = self.df[self.df['ID'] == candidate_id].iloc[0]
        reqs = self.position_reqs[position]

        predictions = {
            'year': ['ç°åœ¨', '1å¹´å', '2å¹´å', '3å¹´å'],
            'è¡¨ç°': [candidate['è¡¨ç°']],
            'æŠ€èƒ½': {},
            'åŸ¹å…»è®¡åˆ’': []
        }

        # æŠ€èƒ½æˆé•¿é¢„æµ‹
        for skill in self.skills:
            current = candidate[skill]
            growth = 0

            if skill in reqs["å¿…éœ€æŠ€èƒ½"]:
                plan = random.choice(self.development_plans[skill])
                predictions['åŸ¹å…»è®¡åˆ’'].append(f"{skill}: {plan}")
                growth = min(0.7, 0.2 + candidate['æˆé•¿æ„æ„¿'] * 0.5)

            predictions['æŠ€èƒ½'][skill] = [
                current,
                np.clip(current + growth * 0.5, 1, 5),
                np.clip(current + growth * 0.8, 1, 5),
                np.clip(current + growth, 1, 5)
            ]

        # è¡¨ç°é¢„æµ‹
        perf_growth = sum(
            (predictions['æŠ€èƒ½'][s][-1] - predictions['æŠ€èƒ½'][s][0]) * w
            for s, w in reqs["æƒé‡"].items()
        ) / sum(reqs["æƒé‡"].values())

        predictions['è¡¨ç°'].extend([
            np.clip(candidate['è¡¨ç°'] + perf_growth * 0.3, 1, 5),
            np.clip(candidate['è¡¨ç°'] + perf_growth * 0.6, 1, 5),
            np.clip(candidate['è¡¨ç°'] + perf_growth, 1, 5)
        ])

        return predictions

    def analyze_optimal_team(self):
        """ç¬¬1å±‚çº§å’Œç¬¬2å±‚çº§çš„ç‹¬ç‰¹æœ€ä½³ç»„åˆæä¾›3ä¸ªæ–¹æ¡ˆ"""
        team_options = []
        used_combinations = set()

        # å€™é€‰äººæ± çš„ç”Ÿæˆï¼ˆæ·»åŠ è°ƒè¯•æ—¥å¿—ï¼‰
        print("\n=== å›¢é˜Ÿç”Ÿæˆè¿‡ç¨‹å¼€å§‹ ===")
        print("ç”Ÿæˆå€™é€‰äººæ± ä¸­...")
        with ThreadPoolExecutor() as executor:
            candidate_futures = {
                pos: executor.submit(self.recommend_candidates, pos, 5)
                for pos, reqs in self.position_reqs.items()
                if reqs["å±‚çº§"] <= 2
            }
            candidates = {}
            for pos, future in candidate_futures.items():
                try:
                    result = future.result()
                    if not result.empty:
                        candidates[pos] = result['ID'].tolist()
                        print(f"âœ… {pos}: è·å–äº†{len(candidates[pos])}åå€™é€‰äºº")
                    else:
                        print(f"âš ï¸ {pos}: æ— å€™é€‰äºº")
                        candidates[pos] = []
                except Exception as e:
                    print(f"ğŸ”¥ {pos} å€™é€‰äººè·å–é”™è¯¯: {str(e)}")
                    candidates[pos] = []

        # æ€»è£å€™é€‰äººæ£€æŸ¥
        if not candidates.get("æ€»è£"):
            print("ğŸ›‘ è‡´å‘½é”™è¯¯: æ— æ€»è£å€™é€‰äºº")
            return []

        # print(f"\næ€»è£å€™é€‰äººæ•°: {len(candidates['æ€»è£']}")

        print("å¼€å§‹ç”Ÿæˆå›¢é˜Ÿ...")

        # å›¢é˜Ÿç”Ÿæˆé€»è¾‘
        max_attempts =100
        attempt_count = 0
        generated_teams = 0

        while generated_teams < 3 and attempt_count < max_attempts:
            attempt_count += 1
            pres = random.choice(candidates["æ€»è£"])
            other_positions = [p for p in candidates.keys() if p != "æ€»è£"]

            team = self._generate_team(pres, candidates, other_positions)
            team_hash = self._create_team_hash(team)

            if team_hash not in used_combinations:
                self._evaluate_team(team)
                team_options.append(team)
                used_combinations.add(team_hash)
                generated_teams += 1
                print(f"ğŸ¯ ç”Ÿæˆæ–°å›¢é˜Ÿ ({generated_teams}/3) - å“ˆå¸Œ: {team_hash}")

        # å›¢é˜Ÿè¯„ä¼°é€‰æ‹©å‰3å
        top_teams = sorted(
            team_options,
            key=lambda x: (x["æŠ€èƒ½è¦†ç›–ç‡"], x["å¤šæ ·æ€§"], -x["é£é™©"]),
            reverse=True
        )[:3]

        print("\n=== å›¢é˜Ÿç”Ÿæˆç»“æœ ===")
        print(f"ç”Ÿæˆå›¢é˜Ÿå€™é€‰æ•°: {len(team_options)}")
        print(f"é€‰æ‹©æœ€ä½³å›¢é˜Ÿæ•°: {len(top_teams)}")

        return self._remove_duplicate_teams(top_teams)

    def _generate_team(self, pres, candidates, other_positions):
        """å›¢é˜Ÿç”Ÿæˆè¾…åŠ©å‡½æ•°"""
        team = {
            "æ€»è£": pres,
            "æˆå‘˜": {},
            "æŠ€èƒ½è¦†ç›–ç‡": 0,
            "å¤šæ ·æ€§": 0,
            "é£é™©": 0,
            "ä¼˜åŠ¿": [],
            "åŠ£åŠ¿": []
        }
        selected = {pres}

        for pos in other_positions:
            available = [c for c in candidates[pos] if c not in selected]
            if available:
                choice = random.choice(available)
                team["æˆå‘˜"][pos] = choice
                selected.add(choice)
                print(f"  â†’ {pos}: æ·»åŠ  {choice}")
            else:
                print(f"  â†’ {pos}: æ— åˆé€‚å€™é€‰äºº")

        return team

    def _evaluate_team(self, team):
        """å›¢é˜Ÿè¯„ä¼°é€»è¾‘ï¼ˆåŒ…æ‹¬ä¼˜åŠ¿/åŠ£åŠ¿åˆ†æï¼‰"""
        member_ids = [team["æ€»è£"]] + list(team["æˆå‘˜"].values())
        team_df = self.df[self.df['ID'].isin(member_ids)]

        # æŠ€èƒ½åˆ†æ
        max_skills = team_df[self.skills].max()
        mean_skills = team_df[self.skills].mean()

        # ä¼˜åŠ¿ï¼ˆå‰3æŠ€èƒ½ï¼‰
        top_skills = mean_skills.nlargest(3)
        team["ä¼˜åŠ¿"] = [
            f"{skill}ï¼ˆå¹³å‡:{value:.1f}/æœ€å¤§:{max_skills[skill]:.1f})"
            for skill, value in top_skills.items()
        ]

        # åŠ£åŠ¿ï¼ˆå2æŠ€èƒ½ï¼‰
        weak_skills = mean_skills.nsmallest(2)
        team["åŠ£åŠ¿"] = [
            f"{skill}ï¼ˆå¹³å‡:{value:.1f}/æœ€å¤§:{max_skills[skill]:.1f})"
            for skill, value in weak_skills.items()
        ]

        # æ•°å€¼æŒ‡æ ‡
        team["æŠ€èƒ½è¦†ç›–ç‡"] = max_skills.mean() / 5
        team["å¤šæ ·æ€§"] = len(team_df['éƒ¨é—¨'].unique()) / len(self.df['éƒ¨é—¨'].unique())
        team["é£é™©"] = 1 - team_df['æ½œåœ¨åŠ›'].mean()

    def _create_team_hash(self, team):
        """ç”Ÿæˆå›¢é˜Ÿçš„å”¯ä¸€å“ˆå¸Œ"""
        members = tuple(sorted([team["æ€»è£"]] + list(team["æˆå‘˜"].values())))
        return hash(members)

    def _remove_duplicate_teams(self, teams):
        """å»é™¤é‡å¤å›¢é˜Ÿ"""
        seen = set()
        unique = []
        for team in teams:
            team_hash = self._create_team_hash(team)
            if team_hash not in seen:
                seen.add(team_hash)
                unique.append(team)
        return unique


# 3. å¯è§†åŒ–å‡½æ•°
def plot_growth(predictions, position):
    # è¡¨ç°é¢„æµ‹
    fig_perf = go.Figure()
    fig_perf.add_trace(go.Scatter(
        x=predictions['year'],
        y=predictions['è¡¨ç°'],
        name='è¡¨ç°',
        line=dict(width=4, color='#1f77b4'),
        marker=dict(size=10)
    ))
    fig_perf.update_layout(
        title=f'{position}çš„æˆé•¿é¢„æµ‹',
        yaxis=dict(range=[1, 5], title='è¡¨ç°è¯„ä»·'),
        xaxis=dict(title='å¹´åº¦'),
        template='plotly_white'
    )

    # æŠ€èƒ½é¢„æµ‹
    fig_skill = go.Figure()
    for skill, values in predictions['æŠ€èƒ½'].items():
        fig_skill.add_trace(go.Scatter(
            x=predictions['year'],
            y=values,
            name=skill,
            mode='lines+markers'
        ))
    fig_skill.update_layout(
        title='æŠ€èƒ½è¿›åŒ–é¢„æµ‹',
        yaxis=dict(range=[1, 5], title='æŠ€èƒ½æ°´å¹³'),
        xaxis=dict(title='å¹´åº¦'),
        template='plotly_white'
    )

    return fig_perf, fig_skill
def display_team_analysis(planner, team, df):
    pres = df[df['ID'] == team["æ€»è£"]].iloc[0]
    members = {pos: df[df['ID'] == eid].iloc[0] for pos, eid in team["æˆå‘˜"].items()}

    st.markdown(f"""
    ## å›¢é˜Ÿæ–¹æ¡ˆçš„ç‰¹ç‚¹
    **æ€»è£å€™é€‰äºº**: {pres['å§“å']} ({pres['éƒ¨é—¨']})  
    **æŠ€èƒ½è¦†ç›–ç‡**: {team["æŠ€èƒ½è¦†ç›–ç‡"]:.0%}  
    **éƒ¨é—¨å¤šæ ·æ€§**: {team["å¤šæ ·æ€§"]:.0%}  
    **é£é™©è¯„ä¼°**: {'ä½' if team["é£é™©"] < 0.3 else 'ä¸­' if team["é£é™©"] < 0.6 else 'é«˜'}
    """)

    # å›¢é˜Ÿæˆå‘˜è¡¨
    member_data = []
    # for pos, member in members.items():
    #     print("#"*100)
    #     print(member[planner.skills])
    #     print("#"*100)
    #
    #     member_data.append({
    #         "èŒä½": pos,
    #         "å§“å": member['å§“å'],
    #         "éƒ¨é—¨": member['éƒ¨é—¨'],
    #         "ä¸»è¦æŠ€èƒ½": ", ".join(member[planner.skills].nlargest(3).index.tolist()),
    #         "ç»¼åˆè¯„åˆ†": f"{planner.recommend_candidates(pos, top_n=10).set_index('ID').loc[member['ID'], 'ç»¼åˆè¯„åˆ†']:.2f}"
    #     })
    # st.table(pd.DataFrame(member_data))
    for pos, member in members.items():
        # ç¡®è®¤æŠ€èƒ½æ˜¯æ•°å€¼æ•°æ®ç±»å‹
        skills = member[planner.skills].astype(float)

        member_data.append({
            "èŒä½": pos,
            "å§“å": member['å§“å'],
            "éƒ¨é—¨": member['éƒ¨é—¨'],
            "ä¸»è¦æŠ€èƒ½": ", ".join(skills.nlargest(3).index.tolist()),
            "ç»¼åˆè¯„åˆ†": f"{planner.recommend_candidates(pos, top_n=10).set_index('ID').loc[member['ID'], 'ç»¼åˆè¯„åˆ†']:.2f}"
        })
    st.table(pd.DataFrame(member_data))

    # ä¼˜åŠ¿å’ŒåŠ£åŠ¿
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("### å›¢é˜Ÿçš„ä¼˜åŠ¿")
        for strength in team["ä¼˜åŠ¿"]:
            st.markdown(f"- {strength}")
    with col2:
        st.markdown("### æ”¹è¿›ç‚¹")
        for weakness in team["åŠ£åŠ¿"]:
            st.markdown(f"- {weakness}")

    # æ¨èç†ç”±
    st.markdown("""
    ### æ¨èç†ç”±
    è¯¥å›¢é˜Ÿç»„åˆåœ¨ä»¥ä¸‹æ–¹é¢è¡¨ç°å‡ºè‰²:
    - è¦†ç›–äº†æ‰€éœ€çš„å¹¿æ³›æŠ€èƒ½
    - ä»å¤šä¸ªéƒ¨é—¨é€‰æ‹”äººæ‰ï¼Œç¡®ä¿å¤šæ ·æ€§
    - å¹³å‡æ½œåœ¨åŠ›é«˜ï¼Œæœªæ¥æˆé•¿å¯æœŸ
    """)

    # é£é™©å› ç´ 
    st.markdown("""
    ### æ³¨æ„ç‚¹
    éœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹:
    - å¯èƒ½ä¾èµ–äºç‰¹å®šæŠ€èƒ½
    - æˆå‘˜ä¹‹é—´çš„ç»éªŒå¹´æ•°å¹³è¡¡
    - ä¸åŒçš„æ²Ÿé€šé£æ ¼
    """)
# 4. ä¸»åº”ç”¨ç¨‹åº
def main():
    try:
        st.set_page_config(layout="wide", page_title="AIç»§ä»»è€…è§„åˆ’å¸ˆ Pro")

        # æ•°æ®å‡†å¤‡
        df, skills, position_reqs = prepare_data()
        planner = SuccessionPlanner(df, skills, position_reqs)

        # æ ‡é¢˜
        st.title('ğŸ¢ AIç»§ä»»è€…è§„åˆ’å¸ˆ Pro')
        st.markdown("""
        **åŸºäºæ–°æŠ€èƒ½ä½“ç³»çš„ä¸‹ä¸€ä»£ç»§ä»»è€…è§„åˆ’ç³»ç»Ÿ**  
        ä»èº«å¿ƒå¥åº·ã€äººæ ¼å’Œå¿—å‘ã€ä»·å€¼è§‚å’Œä¿¡å¿µç­‰å…­ä¸ªæ–¹é¢è¿›è¡Œé€‚åº”æ€§è¯„ä¼°
        """)

        # ä¸»ç•Œé¢
        tab1, tab2 = st.tabs(["ğŸ§‘ ä¸ªäººåˆ†æ", "ğŸ‘¥ å›¢é˜Ÿä¼˜åŒ–"])

        with tab1:
            st.subheader("æŒ‰èŒä½æ¨èå€™é€‰äºº")

            col1, col2 = st.columns([1, 2])
            with col1:
                position_level = st.radio(
                    "èŒä½å±‚çº§",
                    ["ç¬¬1å±‚çº§", "ç¬¬2å±‚çº§", "ç¬¬3å±‚çº§"],
                    horizontal=True,
                    key='pos_level'
                )

                positions = [p for p, req in position_reqs.items()
                             if req["å±‚çº§"] == (1 if position_level == "ç¬¬1å±‚çº§" else 2 if position_level == "ç¬¬2å±‚çº§" else 3)]

                selected_position = st.selectbox("é€‰æ‹©èŒä½", positions, key='pos_select')

                if st.button("åˆ†æå€™é€‰äºº", type="primary", key='analyze_btn'):
                    with st.spinner('æ­£åœ¨åˆ†æå€™é€‰äºº...'):
                        st.session_state.recommendations = planner.recommend_candidates(selected_position)
                        st.session_state.selected_position = selected_position

            # æ˜¾ç¤ºéƒ¨åˆ†çš„ä¿®æ­£
            with col2:
                if 'recommendations' in st.session_state:
                    st.subheader(f"â­ {st.session_state.selected_position} å€™é€‰äººå‰3å")

                    # è°ƒè¯•ä¿¡æ¯æ˜¾ç¤º
                    # st.write("è°ƒè¯•ä¿¡æ¯ï¼ˆåŸå§‹æ•°æ®ï¼‰:")
                    st.write(st.session_state.recommendations)

                    if not st.session_state.recommendations.empty:
                        # fig = px.histogram(st.session_state.recommendations, x='ç»¼åˆè¯„åˆ†',
                        # # fig = px.histogram(st.session_state.recommendations, x='count',
                        #                    title='ç»¼åˆè¯„åˆ†åˆ†å¸ƒ', nbins=20)
                        # st.plotly_chart(fig, use_container_width=True)

                        fig = px.bar(
                            st.session_state.recommendations.sort_values('ç»¼åˆè¯„åˆ†', ascending=False),
                            x='å§“å',
                            y='ç»¼åˆè¯„åˆ†',
                            color='ç»¼åˆè¯„åˆ†',
                            color_continuous_scale='Bluered',
                            title='æŒ‰å€™é€‰äººç»¼åˆè¯„åˆ†',
                            labels={'ç»¼åˆè¯„åˆ†': 'ç»¼åˆé€‚åº”æ€§è¯„åˆ†', 'å§“å': 'å€™é€‰äºº'},
                            hover_data=['éƒ¨é—¨', 'è¡¨ç°', 'æ½œåœ¨è¯„åˆ†', 'æŠ€èƒ½è¯„åˆ†']
                        )
                        # å›¾è¡¨å¸ƒå±€è°ƒæ•´
                        fig.update_layout(
                            xaxis_tickangle=-45,
                            xaxis_title=None,
                            yaxis_range=[0, 1],
                            height=500,
                            hovermode='x unified',
                            coloraxis_showscale=False,
                            margin=dict(b=150))

                        fig.update_traces(
                            texttemplate='%{y:.2f}',
                            textposition='outside',
                            hovertemplate="<b>%{x}</b><br>è¯„åˆ†: %{y:.2f}<br>éƒ¨é—¨: %{customdata[0]}<br>"
                                          "è¡¨ç°: %{customdata[1]:.1f}<br>æ½œåœ¨è¯„åˆ†: %{customdata[2]:.2f}<br>"
                                          "æŠ€èƒ½è¯„åˆ†: %{customdata[3]:.2f}"
                        )
                        st.plotly_chart(fig, use_container_width=True)


                        for idx, row in st.session_state.recommendations.iterrows():
                            with st.expander(
                                    f"{idx + 1}ä½: {row['å§“å']} ({row['éƒ¨é—¨']}) è¯„åˆ†: {row['ç»¼åˆè¯„åˆ†']:.2f}",
                                    expanded=(idx == 0)):
                                col_a, col_b = st.columns([1, 2])
                                with col_a:
                                    # æŠ€èƒ½é›·è¾¾å›¾
                                    fig = go.Figure()
                                    fig.add_trace(go.Scatterpolar(
                                        r=row[skills].values,
                                        theta=skills,
                                        fill='toself',
                                        name='å½“å‰æŠ€èƒ½',
                                        line_color='#636efa'
                                    ))

                                    # èŒä½è¦æ±‚
                                    reqs = position_reqs[st.session_state.selected_position]
                                    fig.add_trace(go.Scatterpolar(
                                        r=[reqs["å¿…éœ€æŠ€èƒ½"].get(s, 0) for s in skills],
                                        theta=skills,
                                        name='èŒä½è¦æ±‚',
                                        line=dict(color='#FFA15A', dash='dot')
                                    ))

                                    fig.update_layout(
                                        polar=dict(radialaxis=dict(range=[0, 5], visible=True)),
                                        title='æŠ€èƒ½æ¯”è¾ƒ',
                                        width=400,
                                        height=400
                                    )
                                    st.plotly_chart(fig, use_container_width=True)

                                with col_b:
                                    st.markdown(f"""
                                    ### æ¨èç†ç”±çš„è¯¦ç»†ä¿¡æ¯
                                    {row['æ¨èç†ç”±']}
                                    #### å®šæ€§æ•°æ®åˆ†æ:
                                    """)
                                    # åé¦ˆæ˜¾ç¤ºï¼ˆå¸¦è½¬ä¹‰å¤„ç†ï¼‰
                                    if 'åé¦ˆ' in row and pd.notnull(row['åé¦ˆ']):
                                        feedback_text = row['åé¦ˆ'].replace('```', 'ï¾Œï¾Ÿï¾›ï½¯ï¾„')  # è½¬ä¹‰Markdownç¬¦å·
                                        st.markdown(f"```\n{feedback_text}\n```")
                                    else:
                                        st.warning("æ²¡æœ‰åé¦ˆä¿¡æ¯")

                                    # {row['åé¦ˆ']}
                                    # è¯¦ç»†åˆ†æ
                        selected_candidate = st.selectbox(
                            "é€‰æ‹©è¦è¯¦ç»†åˆ†æçš„å€™é€‰äºº",
                            st.session_state.recommendations['ID'].tolist(),
                            key='detail_select'
                        )

                        if selected_candidate:
                            st.subheader("ğŸ“ˆ 3å¹´æˆé•¿é¢„æµ‹å’ŒåŸ¹å…»è®¡åˆ’")
                            predictions = planner.predict_growth(selected_candidate, st.session_state.selected_position)

                            # è¡¨ç°é¢„æµ‹
                            st.plotly_chart(plot_growth(predictions, st.session_state.selected_position)[0],
                                            use_container_width=True)

                            # åŸ¹å…»è®¡åˆ’
                            st.markdown("### æ¨èåŸ¹å…»è®¡åˆ’")
                            for plan in predictions['åŸ¹å…»è®¡åˆ’']:
                                st.markdown(f"- {plan}")

                            # æŠ€èƒ½è¿›åŒ–é¢„æµ‹
                            st.plotly_chart(plot_growth(predictions, st.session_state.selected_position)[1],
                                            use_container_width=True)
                    else:
                        st.warning("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å€™é€‰äººã€‚è¯·æ”¾å®½æ¡ä»¶ã€‚")

        with tab2:
            st.subheader("ç®¡ç†å±‚æœ€ä½³ç»„åˆåˆ†æ")
            st.info("AIå°†ä¸ºæ‚¨æ¨èæœ€ä½³çš„æ€»è£å€™é€‰äººå’Œç¬¬2å±‚çº§èŒä½çš„ç»„åˆ")

            if st.button("ç”Ÿæˆæœ€ä½³å›¢é˜Ÿ", type="primary", key='team_btn'):
                with st.spinner('AIæ­£åœ¨åˆ†ææœ€ä½³å›¢é˜Ÿç»„åˆ...'):
                    st.session_state.top_teams = planner.analyze_optimal_team()

            if 'top_teams' in st.session_state:
                for i, team in enumerate(st.session_state.top_teams, 1):
                    with st.expander(f"ğŸ† æœ€ä½³å›¢é˜Ÿæ–¹æ¡ˆ {i}", expanded=i == 1):
                        display_team_analysis(planner, team, df)
    except Exception as e:
        st.error(f"å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}")
        st.write("é”™è¯¯è¯¦æƒ…:")
        st.exception(e)


if __name__ == "__main__":
    main()

